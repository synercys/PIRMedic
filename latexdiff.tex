%DIF 1c1-2
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL buildsys_flat.tex   Sun Aug  4 23:06:41 2024
%DIF ADD tosn_flat.tex       Mon Aug  5 00:31:00 2024
%DIF < \documentclass[format=sigconf,9pt,screen]{acmart}
%DIF -------
\documentclass[manuscript,screen,review]{acmart} %DIF > 
 %DIF > 
%DIF -------
\usepackage[utf8]{inputenc}
\usepackage{balance} 
\usepackage{graphicx}
\usepackage{pifont} \usepackage{xspace}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{subcaption} \usepackage{url, hyperref}
\usepackage{xfrac}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{amsmath,amsthm}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{comment}
\usepackage{xcolor,colortbl, supertabular}
\usepackage{layouts} \usepackage{gensymb} \usepackage{tikz}
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows,shapes}
\usetikzlibrary{tikzmark}
\usetikzlibrary{calc}
\usepackage[normalem]{ulem} 

\usepackage{hhline}
\usepackage{collcell}

\usepackage{tcolorbox}

\usepackage{enumitem}



%
 \newif \ifdraft
\drafttrue 

\newcommand{\akshay}[1]{\ifdraft \textbf{\sffamily\textcolor{purple}{[#1 -- Akshay]}} \else \fi}
\newcommand{\sumukh}[1]{\ifdraft \textit{\textcolor{magenta}{[#1 -- Sumukh]}} \else \fi}
\newcommand{\ashish}[1]{\ifdraft \textcolor{red}{#1 -- Ashish} \else \fi}
\newcommand{\ins}[1]{\ifdraft \textcolor{red}{#1} \else \fi}
\newcommand{\sibin}[1]{\ifdraft \textit{\textcolor{blue}{[#1 -- Sibin]}} \else \fi}


\newcommand{\eg}{{\it e.g.,}\xspace}
\newcommand{\viz}{{\it viz.,}\xspace}
\newcommand{\Eg}{{\it E.g., }}
\newcommand{\etal}{{\it et~al.}\xspace}
\newcommand{\ie}{{\it i.e.,}\xspace}
\newcommand{\etc}{{\it etc.}}
\newcommand{\ci}{{\it (i) }}
\newcommand{\cii}{{\it (ii) }}
\newcommand{\ciii}{{\it (iii) }}
\newcommand{\civ}{{\it (iv) }}
\newcommand{\ca}{{\it (a) }}
\newcommand{\cb}{{\it (b) }}
\newcommand{\cc}{{\it (c) }}
\newcommand{\cd}{{\it (d) }}
\newcommand{\ce}{{\it (e) }}
\newcommand{\cf}{{\it (f) }}
\newcommand{\cg}{{\it (g) }}
\newcommand{\ch}{{\it (h) }}
\newcommand{\cj}{{\it (j) }}
\newcommand{\ck}{{\it (k) }}
\newcommand{\cl}{{\it (l) }}
\newcommand{\cm}{{\it (m) }}
\newcommand{\cn}{{\it (n) }}
\newcommand{\co}{{\it (o) }}
\newcommand{\cp}{{\it (p) }}
\newcommand{\cq}{{\it (q) }}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{53}}
\newcommand{\cout}{$C_{\text{out}}$\xspace}
\newcommand{\aout}{$A_{\text{out}}$\xspace}
\newcommand{\tampered}{$S_{\text{tampered}}$\xspace}
\newcommand{\working}{$S_{\text{working}}$\xspace}
\newcommand{\couttampered}{$C_{\text{out,tampered}}$\xspace}
\newcommand{\coutworking}{$C_{\text{out,working}}$\xspace}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\colorlet{tableheadcolor}{gray!25} \newcommand{\headcol}{\rowcolor{tableheadcolor}} \colorlet{tablerowcolor}{gray!25} \colorlet{tablerowcolor2}{gray!12} \newcommand{\rowcol}{\rowcolor{tablerowcolor}} \newcommand{\rowcollight}{\rowcolor{tablerowcolor2}} 


\newcommand{\highlight}[2]{\colorbox{#1!17}{#2}}
\newcommand{\highlightdark}[2]{\colorbox{#1!47}{#2}}

\newcommand{\sol}{{PIRMedic}\xspace}

\definecolor{ultramarine}{RGB}{68,114,196}
\DeclareRobustCommand\circled[1]{\tikz[baseline=(char.base)]{\node[shape=circle,fill=ultramarine,inner sep=1pt] (char) {\textcolor{white} {#1}};}}

 \AtBeginDocument{\providecommand\BibTeX{{\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF COLORLISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
\date{}
\title{\DIFdelbegin \DIFdel{PIRMedic: Physics-driven }\DIFdelend \DIFaddbegin \DIFadd{Physics-based }\DIFaddend Fault \DIFdelbegin \DIFdel{Diagnosis }\DIFdelend \DIFaddbegin \DIFadd{Analysis }\DIFaddend for \DIFaddbegin \DIFadd{Commodity }\DIFaddend PIR Sensors}
\DIFaddbegin \titlenote{PIRMedic was first introduced as a conference paper in ACM BuildSys~\cite{10.1145/3486611.3486658}. In this work, we expand upon on \sol and provide additional insights on the different classes of faults. We accomplish this by adding a threshold-based technique to study Class I and III faults (\S\ref{subsec:aout_quiet_times}) and including experiments using the threshold algorithm to distinguish between them by evaluation in a cafeteria (\S\ref{subsubsec:cafeteria}). We also study the impact of incremental failures on Class III faults giving insights into impact of gradual degradation on the \aout signal with incremental accumulation of dust(\S\ref{subsec:incremental_dust}). Additionally, we study the impact of different types of foreign particles such as paper and tape on the sensor performance (\S\ref{subsec:foreign_additional}). More generally, we include a quantitative study to compare the impact of various faults on sensor performance (\S\ref{subsec:quantify} and Table~\ref{tbl:fault_degree}). We also study the fault detection accuracy of \sol as a function of pre-deployment training dataset size (\S\ref{subsec:fail_detection}). Lastly, we have study the nature of \aout from ceiling-mount PIR sensors (Fig.~\ref{fig:round_lens}). We have also made some editorial changes by: \ca adding a goals subsection in \S\ref{sec:intro}, \cb updating other physics-related sensor failure related work~\cite{10.1145/3458864.3466869, 10.1145/3576842.3582386}, \cc adding a Frequently Asked Questions (FAQs) summarizing some of the common questions in the appendix and lastly \cd including a 3D visualization of the PIR sensor drawn in Tinker CAD and adding more text explaining the different sensor subsystems.}
\DIFaddend \author{Ashish Kashinath}
\email{ashishk3@illinois.edu}
\DIFdelbegin %DIFDELCMD < \affiliation{\institution{University of Illinois at Urbana-Champaign}
%DIFDELCMD < 	\country{}
%DIFDELCMD < }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \affiliation{\institution{University of Illinois at Urbana-Champaign}
	\country{USA}
}
\DIFaddend \author{Sibin Mohan}
\DIFdelbegin %DIFDELCMD < \email{sibin.mohan@oregonstate.edu}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \email{sibin.mohan@gwu.edu}
\DIFaddend \authornote{Work done while affiliated with University of Illinois at Urbana-Champaign}
\DIFdelbegin %DIFDELCMD < \affiliation{\institution{Oregon State University}
%DIFDELCMD < 	\country{}
%DIFDELCMD < }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \affiliation{\institution{The George Washington University}
	\country{USA}
}
\DIFaddend \author{Akshay Nambi}
\email{akshay.nambi@microsoft.com}
\DIFdelbegin %DIFDELCMD < \affiliation{\institution{Microsoft Research, India}
%DIFDELCMD < 	\country{}
%DIFDELCMD < }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \affiliation{\institution{Microsoft Research}
	\country{India}
}
\DIFaddend 

\author{Sumukh Marathe}
\email{sumukhm@umich.edu}
\authornote{Work done while affiliated with Microsoft Research India}
\DIFdelbegin %DIFDELCMD < \affiliation{\institution{University of Michigan}
%DIFDELCMD < 	\country{}
%DIFDELCMD < }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \affiliation{\institution{University of Michigan}
	\country{USA}
}
\DIFaddend 

 
\begin{abstract}
	Passive Infra-Red (PIR) sensors are \DIFdelbegin \DIFdel{an integral part of modern living. They have diverse }\DIFdelend \DIFaddbegin \DIFadd{ubiquitous and have }\DIFaddend applications ranging from automatic lighting and heating control in smart buildings,  towel dispensers in washrooms, security alarms (for intrusion detection) to \DIFdelbegin \DIFdel{even }\DIFdelend human detection robots (for search and rescue). 
Unfortunately, PIR sensors are prone to failures during deployment due to reasons such as environmental damage, incorrect installation and component degradation among others that can lead to incorrect or faulty data. 
Currently, such failures are typically detected using either : \ca heavily engineered data-driven, statistical approaches that can have high false positive rates due to unseen data patterns or \cb expensive\DIFaddbegin \DIFadd{, unscalable }\DIFaddend methods that use additional hardware such as video cameras or a golden reference sensor.
\DIFdelbegin \DIFdel{The second approach inhibits scalability.
}%DIFDELCMD < 

%DIFDELCMD < 	%%%
\DIFdelend In this work, we first create a \textit{taxonomy} for the most common PIR sensor failures \DIFaddbegin \DIFadd{and analyze these failures from the perspective of sensor physics}\DIFaddend .
We then present \sol --- a \textit{physics-driven\DIFdelbegin \DIFdel{approach}\DIFdelend , \DIFdelbegin \DIFdel{implemented at the edge,}\DIFdelend \DIFaddbegin \DIFadd{edge-based approach}\DIFaddend } to \DIFdelbegin \DIFdel{detect the various classes of failures.
We show that we can both }\DIFdelend \textit{detect} and \textit{diagnose} the failures in a PIR sensor using an intrinsic hardware signal~\viz the analog output from the pyroelectric element in the sensor. 
Using this hardware signal in conjunction with frequency analysis and supervised machine learning methods, we obtain a high accuracy of $98-99 \%$ in failure detection and diagnosis. 
We evaluate our methods using \textit{\DIFaddbegin \DIFadd{multiple }\DIFaddend real-world deployments\DIFdelbegin %DIFDELCMD < \MBLOCKRIGHTBRACE %%%
\DIFdel{in three }\DIFdelend \DIFaddbegin }\DIFadd{, in four }\DIFaddend distinct locations, in different environment and usage conditions.    
\end{abstract}


\begin{comment}
\begin{abstract}
    Most IoT/cyber-physical applications depend on the correct functioning of sensors.
Failures in such sensors are typically detected using heavy data-driven approaches (that can have high false positive rates) or expensive methods that use additional hardware (\eg video cameras) but lack in scalability.
In this work, we first create a \textit{taxonomy of faults} for IoT sensors with the passive infrared (PIR) sensor as an exemplar for such devices.
We then present a \textit{physics-driven approach} to detect the various classes of failures, some of which are hard to detect due to the physical degradation of the devices over time.
We show that we can both \textit{detect} and \textit{rootcause} the failures using a hardware signal intrinsic to a PIR sensor \viz the analog output from the pyroelectric element in the sensor.
Using this hardware signal in conjunction with frequency analysis and supervised machine learning methods, we obtain a high accuracy in failure detection and diagnosis for such sensors, \viz $98-99 \%$. 
We evaluate our methods using \textit{real-world deployments} in four distinct locations across two continents, in different environment and usage conditions.    
\end{abstract}
\end{comment}

\begin{comment}

\begin{abstract} Passive Infrared (PIR)-based occupancy sensors are widely used in Cyber-Physical/IoT applications such as factory floors and conference rooms. Currently, failures in PIR sensors are detected by expensive data-driven techniques such as time correlations with secondary sensors~\eg video cameras or by performing periodic calibration against a golden, reference sensor. This approach of using additional sensors is both expensive and lacks in scalability. In addition, current practice of sensors deployments is to refresh them after a defined time duration(\eg 10 years in our building). There is no standard diagnosis of failed sensors and no analysis of degradation if any, for these sensors.

In this work, we \ca use a physics-driven systems approach to study the impact of various practical failures (validated with Building IoT technicians), \cb develop a taxonomy of failures and \cc devise a technique for fault detection and diagnosis -- all for a PIR sensor. We show that we can both \textit{detect and rootcause} the failures using a hardware signal intrinsic to a PIR sensor \viz the analog output from the pyroelectric element in the sensor. Using this hardware signal in conjunction with frequency analysis and supervised machine learning methods, we are able to obtain a high accuracy of 98-99\% of failure detection and diagnosis. We validate our technique using deployments in the wild over a duration of 3 months -- \ci in a cafeteria during lunchtime, \cii in our university building and \ciii at a starbucks coffee shop. We use this research to make recommendation to PIR sensor vendors to make this signal widely available.



\end{abstract}

\end{comment} \DIFdelbegin %DIFDELCMD < \acmYear{2021}\copyrightyear{2021}
%DIFDELCMD < \setcopyright{acmlicensed}
%DIFDELCMD < \acmConference[BuildSys '21]{ACM International Conference on Systems for Energy-Efficient Built Environments}{November 17--18, 2021}{Coimbra, Portugal}
%DIFDELCMD < \acmBooktitle{ACM International Conference on Systems for Energy-Efficient Built Environments (BuildSys '21), November 17--18, 2021, Coimbra, Portugal}
%DIFDELCMD < \acmPrice{15.00}
%DIFDELCMD < \acmDOI{10.1145/3486611.3486658}
%DIFDELCMD < \acmISBN{978-1-4503-9114-6/21/11}
%DIFDELCMD < 

%DIFDELCMD < \begin{CCSXML}
%DIFDELCMD < 	%%%
\DIFdel{<ccs2012>
	<concept>
	<concept_id>10010520.10010553</concept_id>
	<concept_desc>Computer systems organization~Embedded and cyber-physical systems</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010583.10010750.10010751</concept_id>
	<concept_desc>Hardware~Fault tolerance</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
}%DIFDELCMD < \end{CCSXML}
%DIFDELCMD < 

%DIFDELCMD < \ccsdesc[500]{Computer systems organization~Embedded and cyber-physical systems}
%DIFDELCMD < \ccsdesc[500]{Hardware~Fault tolerance}
%DIFDELCMD < \keywords{Passive Infra-Red (PIR) Sensors, Fault Diagnosis, Fault Detection, Fault Isolation, Cyber-Physical Systems, Edge ML, Reliability} %%%
\DIFdelend \maketitle
\section{Introduction}
\label{sec:intro}

\DIFdelbegin \DIFdel{IoT applications deployed in }\DIFdelend \DIFaddbegin \DIFadd{Cyber-Physical and IoT Systems such as }\DIFaddend smart homes, industrial control and healthcare systems \DIFaddbegin \DIFadd{often }\DIFaddend require the correct functioning of a myriad set of sensors. 
\DIFdelbegin \DIFdel{The data from these sensors is used by }\DIFdelend \DIFaddbegin \DIFadd{These sensors measure the surrounding environment in the form of either an arithmetic value (}\eg \DIFadd{temperature of 72}\degree \DIFadd{F) or a logical value (}\eg \DIFadd{presence or absence of smoke) and, trigger computations and actions.
Typically, these sensor data measurements are used by data-driven }\DIFaddend IoT analytics pipelines \DIFdelbegin \DIFdel{to derive patterns, }\DIFdelend \DIFaddbegin \DIFadd{(}\eg \DIFadd{Microsoft Azure IoT) to derive }\DIFaddend insights and make \DIFaddbegin \DIFadd{higher-level }\DIFaddend decisions. 
One of the most versatile and ubiquitous sensors used in numerous modern applications is a Passive Infra-Red (PIR) sensor.
A PIR sensor is a discrete, electronic sensor that captures thermal radiation from human and human-like objects (\eg animals) to indicate occupancy in a region. They are used in a \DIFdelbegin \DIFdel{wide variety of environments , from building automation to }\DIFdelend \DIFaddbegin \DIFadd{wide-variety of environments -- }\eg \DIFadd{in offices to achieve energy savings in buildings (for automatic control of lighting and HVAC systems) and in }\DIFaddend safety-critical \DIFdelbegin \DIFdel{systems such as factories.
Consequently, the correct operation of PIR sensors is critical to the quality and performance of many IoT deployments}\DIFdelend \DIFaddbegin \DIFadd{cyber-physical systems (CPS) like factory floors for intrusion detection.
Naturally, these applications mandate the correctness and fidelity of data }\ie \DIFadd{the data being a faithful representation of occupancy}\DIFaddend .


Given the nature of PIR deployments in the wild : for instance in remote, manually inaccessible, harsh conditions (\eg assembly line of a factory), they are prone to failures and degradation of physical components.
These failures could result in false triggers or a failure to capture real movements \eg assembly line failures in a factory\DIFdelbegin \DIFdel{or }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend inaccurate estimation of wildlife counts\DIFaddbegin \DIFadd{, conference room lights turning off or even doors not opening in spite of occupancy}\DIFaddend .
Such sensor failures are often caused by intermittent sensor faults that can happen in any one of its internal physical components~\cite{chakraborty2018fall,marathe2021currentsense}.











\DIFdelbegin %DIFDELCMD < \begin{figure}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \begin{wrapfigure}{R}{0.5\textwidth}
    \DIFaddendFL \centering
    \DIFdelbeginFL %DIFDELCMD < \begin{minipage}[b]{\columnwidth} \scalebox{0.8}{
%DIFDELCMD < 		\centering
%DIFDELCMD < \includegraphics[width=\textwidth]{figures/motivation/motivation-physics-technique.png}}
%DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=0.5\textwidth]{figures/motivation/motivation-physics-technique.png}
    \DIFaddendFL \caption{\footnotesize{Sensor Data} from a working PIR (top) and a faulty PIR (bottom). HIGH indicates no object, \DIFdelbeginFL \DIFdelFL{HIGH->}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{HIGH$\rightarrow$}\DIFaddendFL LOW transition indicates object.}
    \label{fig:occupancy_sensor_data}
\DIFdelbeginFL %DIFDELCMD < \vspace{-18pt}
%DIFDELCMD < 	\end{minipage}\end{figure} 
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \end{wrapfigure}
\DIFaddend 







Currently, failures in PIR sensor deployments are usually addressed in one of the following two ways : \ca using an additional, auxiliary sensor such as a CCTV camera combined with image processing algorithms (say to validate the occupancy data) or \cb using high-grade PIR sensors that possesses additional capabilities such as ultrasonic sensors and intricate optics. This makes the sensor deployment very expensive. In addition, deployments need to be refreshed periodically by replacing old sensors with new ones and the former are disposed off adding to both electronic waste and cost. A case in point is our university research building where the occupancy sensor deployed is a high-grade PIR sensor comprising both ultrasonic and infrared sensors, resulting in a \emph{total recurring cost of close to \$100000 every 10 years}\footnote{Our 4-floor building (with a total of 244 rooms and 24 aisle areas) has more than 300 occupancy sensors. Each PIR sensor costs \$300~\cite{hubbell_ADT1600WRP, hubbell_ATD2000CRP} with it being refreshed every 10 years, a worst-case recurring cost of \$90000 every 10 years, which is expensive.}.


\begin{comment}
\begin{wrapfigure}{L}{6cm}
	\centering
	\vspace{-10pt}
	\includegraphics[width=0.4\columnwidth]{figures/motivation/motivation-physics-technique.png}
	\caption{\textbf{Occupancy Sensor Data} from a working sensor (top) and a degraded sensor with some dust deposited on the lens (bottom). The output follows negative logic \viz 0 -- object, 1 -- no object.}
\label{fig:motivation_physics}
	\vspace{-10pt}
\end{wrapfigure}
\end{comment}

Crucially, \textit{current approaches do not diagnose the cause of failures or perform any analysis of sensor performance}, that can be valuable for IoT engineers during maintenance, repair and testing. For example, in one of our deployments, we observed that failed or degraded sensors can exhibit unpredictable behavior \eg they can work temporarily for a period of time and then fail sometimes. {\bfseries  Fig.~\ref{fig:occupancy_sensor_data}} shows a plot of output data from the sensor vs. time for both a working sensor and a faulty sensor (defective lens) over a period of 4 hours.
In this plot, a transition from HIGH$\rightarrow$LOW denotes a person coming into the field of view and a value of HIGH indicates that there is no person. We observe that the faulty sensor works intermittently and at other times, can miss a person (false negative) or incorrectly flag the presence of a person (false positive).
Missing a person can cause a potentially critical failure in applications such as door opening systems or emergency shutdowns on factory floors.
We show that accurate detection of such failures is possible by \textit{characterizing the internals of the sensor.}




\begin{comment}
    \begin{tcolorbox}[left=0.05pt,right=0.05pt,top=0.05pt,bottom=0.05pt,boxsep=0pt,toptitle=0ex,bottomtitle=0ex,sharp corners]
    {\bfseries Summary:} Existing solutions for reliability in IoT sensors: \ci require additional, auxiliary sensors, \cii do not diagnose failures, and \ciii add to electronic waste, resulting in large recurring cost.
    \end{tcolorbox}
\end{comment}


\emph{Our solution, \sol detects and diagnoses failures of PIR sensors by characterizing the physics of sensing} \viz the fresnel lens optics and the pyroelectric effect. To keep the cost of the deployment low, \sol is implemented on the edge platforms of the deployment and targets \DIFdelbegin \DIFdel{cheap }\DIFdelend \DIFaddbegin \DIFadd{commodity }\DIFaddend PIR sensors.
In this process, we \emph{devised a taxonomy of key failures for aiding diagnosis and repair.} 


Specifically, we demonstrate that a signal intrinsic to PIR sensors~\viz the \textit{intermediate analog output from the pyroelectric element, referred to as \aout} ({\bfseries Fig.~\DIFdelbegin \DIFdel{\ref{fig:pir_working}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:pir_sensing_pipeline}}\DIFaddend }) can be used for fault detection and diagnosis. We utilize this signal to derive information about \DIFdelbegin \DIFdel{the }\DIFdelend reliability of the PIR sensor platform as well as \DIFaddbegin \DIFadd{to }\DIFaddend perform an analysis into the different failure modalities. \textit{To the best of our knowledge, this is the first edge-based, low-cost approach to use an intrinsic signal (\aout) for fault detection and diagnosis of PIR sensors.} We analyze the behavior of \aout in detail, under practical deployments, with realistic occupancy
over a wide variety of observed failures. 


\noindent \textbf{Summary of Contributions:}
\begin{enumerate}[leftmargin=*]
	\itemsep0pt
    \item \textit{From physics to failures:} We use the working of a PIR sensor to understand the process of object detection and infer the key points where failures \DIFaddbegin \DIFadd{could }\DIFaddend lead to incorrect sensor data,
    \item \textit{Failure taxonomy:} We \DIFdelbegin \DIFdel{systematize of key failures that can occur in a PIR sensor to develop a }\DIFdelend \DIFaddbegin \DIFadd{study the impact of different failures on the sensor performance and systematize the key failures into a }\DIFaddend failure taxonomy. \DIFaddbegin \DIFadd{We also provide a quantitative method to study the severity of failures.
}\DIFaddend 


    \item \textit{Non-intrusive, online fault detection and diagnosis:} We present an online technique (does not require any disassembling), \emph{implemented at the edge}, for failure detection as well as diagnosis by utilizing the intermediate, analog output from the pyroelectric element in the PIR sensor (\aout). 
\item \textit{Insights from Real-world Deployments:} We show the efficacy of the proposed techniques using a deployment of 15 PIR sensors in \DIFaddbegin \DIFadd{four }\DIFaddend practical occupancy scenarios \DIFdelbegin \DIFdel{(elevator, lobby of a building and at starbucks)
}\DIFdelend over a period of 3 months.
\end{enumerate}



\begin{comment}
\subsection{Assumptions}
\quad \underline{\bfseries Target System:} We consider PIR sensor deployments that are: \ca large in scale, \cb deployed remotely (making manual checking of faults hard), \cc consisting of low cost and \cd commodity off the shelf (COTS) sensors, such as those in modern smart buildings.


\underline{\bfseries Choice of sensor:} As our work leverages the \aout signal present in a PIR sensor, we require a PIR sensor that allows access to \aout either directly or indirectly by reworking the sensor such as ~\cite{PIR_sensor_eval}. While this limits the scope of our work, our framework can form the basis for manufacturers and IoT engineers for leveraging the rich information in \aout for inclusion in future designs.


\underline{\bfseries Existence of ground truth:} We perform our analysis of the occupancy patterns by gathering data from multiple different sensors, some of which can fail or degrade. However, we assume that not all sensors fail simultaneously as it enables us to separate physics of failed sensors from physics of working sensors. This is a reasonable assumption due to the large-scale nature of deployment.

\underline{\bfseries Security of sensor values:} We perform our analysis of sensors at the edge, and assume that the sensor data are not tampered with using attacks such as Man-in-the-Middle attacks (MitM) or using software vulnerabilities in the edge platform.
\end{comment}

\DIFaddbegin \noindent \textbf{\DIFadd{Goals:}}

\begin{enumerate}[leftmargin=*]
	\itemsep0pt

\item {\itshape \DIFadd{Detect failures:}} \DIFadd{Sensors can give faulty data due to the incorrect operation of various physical components involved in the sensing process. We seek to detect and isolate such failed sensors. 
}

\item {\itshape \DIFadd{Diagnose failures:}} \DIFadd{In addition to detecting failures, we perform failure diagnosis to identify the cause of the failure. We use domain-knowledge of the sensing physics and our understanding of how different failures can impact the physics. This aids in repair and performing quality-control checks.
}


\item {\itshape \DIFadd{Edge-based solution:}} \sol \DIFadd{is tailored for edge platforms (Raspberry Pi, Arduino Microcontrollers) that are interfaced directly to multiple sensors, say via GPIO. Edge-based reliability solutions allows us to reject data from faulty sensors in IoT deployments thus saving the cost of both }\ca \DIFadd{the edge to cloud network bandwidth and }\cb \DIFadd{cloud compute consumed by faulty data.
}


\item {\itshape \DIFadd{Target Audience:}} \sol \DIFadd{benefits two sections of the community: }\ca \DIFadd{engineers developing and deploying IoT/Edge computing for occupancy sensors (}\eg \DIFadd{Smart Buildings), }\cb \DIFadd{manufacturers of occupancy sensors can use the insights from this work towards future PIR sensor hardware designs.
}

\end{enumerate}

\DIFaddend \begin{comment}
Sensors are the bridge between the compute domain and the physical domain. They provide a manifestation of the physical domain to the compute domain wherein the computation is then be performed. The result of this computation is then utilized to make changes to the physical domain. For example, when a user moves his palm under a faucet with an in-built sensor, it triggers a signal to open a valve that pours water onto his palms. This closed loop of $physical\_environment \rightarrow sensor \rightarrow compute \rightarrow actuator \rightarrow physical\_environment$, seen in all sensing systems excludes reliability measures such as failure detection and sensor drift. As a result, we currently piggyback techniques such as data-driven anomaly detection \cite{hill2010anomaly} and schemes as calibration \cite{maag2018survey} to existing systems to achieve reliability and confidence in the data.  Additionally, present techniques for hardware fingerprinting apply to a restricted class of sensors - analog sensors, which operate by periodically sampling a quantity of interest and where the voltage variation between the on and off states are high enough to be characterized. 



In this paper, we present an automated, low-cost approach to fault detection in digital sensors, performed at the edge, without user intervention. We perform this by analyzing sensors which are outside the purview of the \textit{Fall-curve} \cite{chakraborty2018fall} technique. As sensors vary in nature by the phenomena being sensed, leading to different physics of operation, and hardware signals, there is no single silver bullet to detect faults. Instead, we present a suite of techniques based on most commonly found faults in the wild. 


\newenvironment{myquotation}{\setlength{\leftmargini}{1.5em}\quotation}{\endquotation}
\begin{myquotation}
	\noindent\textit{We present a principled approach to making digital sensors "reliable" - overcoming the challenges of capturing fall curve \cite{chakraborty2018fall} and finding alternative approaches to capture the hardware fingerprint of the sensor.}
\end{myquotation}

\noindent \textbf{Scope} We consider digital sensors out there are low cost, used in large scale, and are deployed in remote and harsh environments. From an application standpoint, we looked at sensors that are used in environmental monitoring.




\end{comment} \DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \section{Related Work} 
\label{sec:related}





\begin{comment}
\begin{table*}
	\centering
\caption{Overview of related work in the space of sensor fault detection}
\begin{tabular}{p{2cm} | p{2.5cm}p{4cm}p{1cm}p{3cm}p{3cm}}
\hline
		\bfseries \textsc{State of the Art} & 
		\bfseries \textsc{Approach} & 
		\bfseries \textsc{Remarks} & 
		\bfseries \textsc{Cost} & 
		\bfseries \textsc{Practicality} & 
		\bfseries \textsc{Notes} \\
		\hline \hline
		
		\rowcolor{gray!20} Khalastchi~\etal~\cite{} & 
		Data-driven + Model-based & 
		Requires suspicious patterns capturing the correlation of sensors. Applies to only stuck/drift faults. & 
		Moderate & 
		Shown on a single system &
		DS/ML \\
		
		Joerger and Pervan~\etal~\cite{} &
		Control Theoretical (Kalman Filter) &
		Monitoring state estimation errors &
		High &
		Shown in simulations only &
		Linear Dynamical systems \\
		
		\rowcolor{gray!20} Liu~\etal~\cite{} &
		Data-driven + Statistical filtering/recovery &
		Used for data errors such as timing, formatting and outliers &
		Moderate, heavy pre-engineering &
		Shown on a single system &
		Data recovery/cleaning and not fault diagnosis is the goal \\
		
		Ayadi~\etal~\cite{}, Elnahrawy~\etal~\cite{}, Koushanfar~\etal~\cite{}, Murphree~\etal~\cite{}, Ni~\etal~\cite{}, Niggemann~\etal~\cite{}, O'Reily~\etal~\cite{}, Power~\etal~\cite{}, Rashid~\etal~\cite{}, Sharma~\etal~\cite{}, Subramaniam~\etal~\cite{}, Wu~\etal~\cite{} &
		Data-driven environmental model &
		&
		&
		&
		\\
		
		\rowcolor{gray!20}Khoussainova~\etal~\cite{}, Krishnamachari~\etal~\cite{}, Ni~\etal~\cite{}, Sheng~\etal~\cite{}, Tolle~\etal~\cite{} &
		Estimation-based methods &
		&
		&
		&
		\\
		
		Maag~\etal~\cite{}, Whitehouse~\etal~\cite{}, Tang~\etal~\cite{}, Dorffer~\etal~\cite{}, Wang~\etal~\cite{}, Saukh~\etal~\cite{}, Xiang~\etal~\cite{}, Yan~\etal~\cite{} &
		Calibration-based methods &
		&
		&
		&
		\\
		
		\rowcolor{gray!20} Chakraborty~\etal~\cite{}, Liu~\etal~\cite{} &
		Hardware-based techniques &
		&
		&
		&
		\\
		
		
		
		
		\hline 
	\end{tabular}\\
	\vskip1pt 
	\quad \raggedright 
	$^1$ called inter-arrival time for sporadic and aperiodic flows
\label{tbl:flow_para}
	\vspace{-1.5\baselineskip}
\end{table*}
\end{comment}




Current solutions for failure detection and diagnosis in sensors fall into one of three categories -- \ca Data-driven techniques, \cb Calibration-based techniques and \cc Fingerprint-based techniques.

\textbf{Data-driven techniques.} Prevalent research efforts have largely focused on data-centric approaches (rule-based or anomaly detection), where historical data of the sensor is analyzed and a fault is identified if the data is out of bounds of the expected behavior~\cite{rashid2016collect, 10.1145/3365871.3365872}.  Sharma~\etal~\cite{10.1145/1754414.1754419}, proposed a multiplicative seasonal ARIMA time series model for fault detection, where the parameter captures periodic behavior in the sensor data. The downside of temporal analysis methods is that
they are prone to false positives and are not feasible in long-term
deployments. Wu~\etal~\cite{4262542} used a spatial mining-based approach that uses spatial correlation between neighbouring sensors to detect anomalies. Additionally, techniques such as Ayadi~\etal~\cite{7505190}, Murphree~\cite{7589589} and Power~\etal~\cite{10.1145/3365871.3365872} require significant labeled data as it models only the environment and does not model the sensor physics. Estimation-based methods model normal sensor behavior leveraging spatiotemporal correlation and probabilistic models such as Bayesian or Gaussian distributions~\cite{10.1145/1140104.1140114} and they work well in homogeneous environments. \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{In a nutshell, the key challenge with data-driven techniques is that it relies on rules and patterns in the sensed data.
}\DIFaddend We argue that for PIR sensors since the data is non-periodic and dependent on deployment scenarios (\eg people counting in \DIFdelbegin \DIFdel{starbucks}\DIFdelend \DIFaddbegin \DIFadd{Starbucks}\DIFaddend ,   
animal detection in forests, etc.), \textit{it is non-trivial to detect faults by just analyzing sensor data.} Further, this requires significant manual efforts and tailor-made rules to detect faults, and can eventually have high false positives due to unseen data patterns. \DIFaddbegin \DIFadd{Additionally, data-driven techniques do not provide information about the specific nature or degree of failure in the sensor. As a result, they do not aid in the process of developing repair strategies.	
}\DIFaddend 

\textbf{Calibration-based techniques.} These techniques rely on the presence of an additional (reference) sensor, either to perform periodic calibration~\cite{whitehouse2002calibration, 8405565} or carrying additional information in a different domain space.  \Eg using a camera to cross-check the data of a PIR sensor~\cite{tang2017occupancy}. Numerous algorithms have been developed for performing calibration such as blind calibration~\cite{7472216, 7495010}, collaborative calibration~\cite{10.1145/2737095.2737113, 10.1145/2185677.2185687} and transfer calibration~\cite{article_nose}. However, using reference sensors is an expensive strategy that lacks scalability for large IoT deployments or those in developing countries.

\textbf{Fingerprint-based techniques.} Chakraborty~\etal~\cite{chakraborty2018fall} develop a sensor signature~\viz ``Fall Curve'' that measures a sensor's voltage response when the power is turned off, to detect faults in periodic on-off based analog sensors. 
\DIFaddbegin \DIFadd{The Fall Curve characterizes the parasitic capacitance and hardware circuitry of the sensor. Crucially, Chakraborty }\etal \DIFadd{show this signature is unique for every sensor type and is independent of the environment. They demonstrate that this approach works well for sensors that have very little or no warm-up time and work in a periodic on-off fashion. 
Furthermore, Chakraborty }\etal \DIFadd{\mbox{%DIFAUXCMD
\cite{chakraborty2018fall} }\hskip0pt%DIFAUXCMD
point out to the fact that extending this approach to digital sensors where one doesn't have direct access to the analog signal is challenging. Additionally, Fall Curve is complex in sensors having low value of operating voltages and lack periodicity in the sensing mechanism. Our work concerns this design space of exploring faults in discrete-valued PIR sensors. PIR sensors are challenging since in addition to being discrete valued, the internal analog signal~}\viz \DIFadd{output from the pyroelectric element has a very low value. 
}\DIFaddend Similarly, Tambe~\etal~\cite{10.1145/3458864.3466869} show a variant of Fall \DIFdelbegin \DIFdel{curve, i.e., ``Fall time}\DIFdelend \DIFaddbegin \DIFadd{Curve~}\ie \DIFadd{``Fall Time}\DIFaddend '' of the analog signal can detect faults and drifts in phototransistor components of the sensor.
However, both Fall Curve and Fall \DIFdelbegin \DIFdel{time signatures does }\DIFdelend \DIFaddbegin \DIFadd{Time signatures do }\DIFaddend not work on certain types of sensors including PIR, that operate under low voltages and are event-triggered. Marathe~\etal~\cite{marathe2021currentsense} show that analyzing the current profiles of a digital sensor can provide insights into component failures especially in electro-mechanical sensors. However, this approach is limited to power-hungry digital sensors. \DIFaddbegin \DIFadd{Gupta~}\etal\DIFadd{~\mbox{%DIFAUXCMD
\cite{10.1145/3576842.3582386} }\hskip0pt%DIFAUXCMD
develop a Verified Telemetry SDK (VT-SDK) constructed on robust sensor fingerprinting algorithms and demonstrate fault detection on multiple sensors ranging from air pollution to pressure sensors.
There are other hardware-based techniques such as Liu~}\etal\DIFadd{~\mbox{%DIFAUXCMD
\cite{Liu_Huang_Luo_Harkin_McDaid_2019} }\hskip0pt%DIFAUXCMD
that detects electronic faults by developing additional circuits inspired by the biology of neurons.
}\DIFaddend 

PIR sensors are challenging since in addition to being discrete-valued, the internal analog signal output from the pyroelectric sensor has a very low value, often oscillating between 1--1.8V. We show that the intermediate analog output (\aout) from the PIR sensor carries interesting insights on the characteristics of the sensor. Narayana~\etal~\cite{narayana2015pir} leveraged this signal by developing a customized sensor array for performing localization and studying object metrics. \DIFaddbegin \DIFadd{They develop a customized sensor tower consisting of a strategic geometric arrangement of multiple PIR sensors to enable capturing the analog signal from those multiple sensors. They use this to study the object size (height and width) and posture (such as its distance from the sensor and the direction of motion) and its impact on features of the analog signal such as frequency, amplitude, phase and time difference between peaks. 
}\DIFaddend However, Narayana~\etal~\cite{narayana2015pir} do not explore reliability.


















 

\DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \begin{wrapfigure}{R}{0.25\textwidth}   
\centering
        \includegraphics[width=0.2\textwidth, height=1.3in]{figures/platform/3d_view_5-annotated.jpg}
        \caption{\DIFadd{PIR Sensor Teardown showing the different subsystems illustrated in TinkerCAD}}
        \label{fig:pir_system_teardown}
\end{wrapfigure}

\DIFaddend \section{PIR Sensors}
\label{sec:approach}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{In this section, we briefly describe the working of a PIR sensor and then present the potential failure scenarios in PIR sensors}\DIFdelend \DIFaddbegin \DIFadd{We take a deep dive into a PIR sensor with 3 goals -- }\ca \DIFadd{understanding the physics of sensing (\S\ref{subsec:physics}, \S\ref{subsec:working}), }\cb \DIFadd{correlating physics to the failure scenarios (\S\ref{subsec:taxonomy}) and }\cc \DIFadd{analyzing the effect of these failures on the sensing performance (\S\ref{subsec:quantify})}\DIFaddend .



\DIFdelbegin %DIFDELCMD < \begin{figure}
%DIFDELCMD < 	\begin{minipage}[b]{\columnwidth} \scalebox{0.8}{}
%DIFDELCMD < 		\centering
%DIFDELCMD < 		\includegraphics[width=0.8\textwidth]{figures/platform/pir-block-diagram-2-redraw-camera.png}
%DIFDELCMD < 		\vspace{-5pt}
%DIFDELCMD < 		%%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{Internal components of a PIR sensor.}%%%
}
		%DIFAUXCMD
%DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < 		\label{fig:pir_working}
%DIFDELCMD < 	\end{minipage}\end{figure} 
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \subsection{Background}
\DIFdelbegin \DIFdel{A PIR sensorinternally comprises of 3 subsystems as }\DIFdelend \DIFaddbegin \label{subsec:physics}
\DIFadd{The teardown of a PIR sensor, showing the internal components is }\DIFaddend shown in {\bfseries Fig.\DIFdelbegin \DIFdel{\ref{fig:pir_working}}\DIFdelend \DIFaddbegin \DIFadd{~\ref{fig:pir_system_teardown}}\DIFaddend }\DIFaddbegin \DIFadd{.
It comprises 3 subsystems }\DIFaddend -- \ca a lens, \cb a pyroelectric \DIFaddbegin \DIFadd{attached to an optical filter}\DIFaddend , and \cc an electronic subsystem.
These subsystems act in sequence \ie Lens $\rightarrow$ Pyroelectric $\rightarrow$ Electronic to perform the end-to-end sensing process as \DIFdelbegin \DIFdel{we describe }\DIFdelend \DIFaddbegin \DIFadd{shown in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensing_pipeline}}}\DIFadd{. We describe the different subsystems }\DIFaddend next.


\noindent \underline{\bfseries Lens Subsystem} A plastic fresnel lens~\cite{an_murata} is used to capture and \DIFaddbegin \DIFadd{precisely }\DIFaddend focus thermal radiation into an optical filter that is aimed at a pyroelectric element. 
Fresnel lenses have a large capture area (aperture) and are used to concentrate radiation into a narrow beam. \DIFaddbegin \DIFadd{They are used to divide the entire region observable to the PIR sensor into small cells, which increases range of the sensor by manifolds. 
They have a large capture area (aperture) and are common in a wide variety of applications such as lighthouses, solar cells and even in optical landing systems in aircrafts~\mbox{%DIFAUXCMD
\cite{webster1999measurement}}\hskip0pt%DIFAUXCMD
.
}\DIFaddend 






\DIFdelbegin %DIFDELCMD < \begin{figure}[t!]
%DIFDELCMD < 	\begin{minipage}[b]{\columnwidth}
%DIFDELCMD < 		\centering
%DIFDELCMD < 	\includegraphics[width=0.6\textwidth]{figures/lens_types/inline_lens.png}
%DIFDELCMD < 	\vspace{-10pt}
%DIFDELCMD < 		%%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{Output signals \aout (Green) and \cout (Blue)} %%%
\DIFdelFL{during sensor operation. }%DIFDELCMD < \aout%%%
\DIFdelFL{, (magnified) shows oscillations when an obstacle is detected.}}
		%DIFAUXCMD
%DIFDELCMD < \label{fig:pir_output}
%DIFDELCMD < 	\end{minipage}\vspace{-15pt}
%DIFDELCMD < \end{figure} 
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \noindent \underline{\bfseries Pyroelectric Subsystem} comprises of an optical filter and a pair of pyroelectric elements. The optical filter is designed to filter out thermal radiations from wavelengths outside the human range (i.e., ~ 5 $\mu$m to 10 $\mu$m), which is then incident on the pyroelectric elements. The pyroelectric elements convert the thermal radiation into an electrical voltage signal, a process known as the \textit{pyroelectric effect}. The output of the pyroelectric subsystem is an analog signal that is sent to the electronic subsystem.
\DIFaddbegin \DIFadd{In practice, there are two pyroelectric elements connected in series in a differential configuration. This differential configuration enables the PIR sensor to detect }\textit{\DIFadd{movement}} \DIFadd{of objects as static objects will trigger both the pyroelectric elements equally and cancel out unlike moving objects that trigger both elements unequally resulting in an output from the pyroelectric subsystem. Due to the differential output voltage, the pyroelectric subsystem does not measure the absolute intensity of incident thermal radiation but measures a change in incident thermal radiation, say caused by motion. Note that the pyroelectric element by itself is passive }\ie \DIFadd{has no power source.
}\DIFaddend 



\noindent \underline{\bfseries Electronic Subsystem} consists of a filter (RC \DIFdelbegin \DIFdel{filters}\DIFdelend \DIFaddbegin \DIFadd{filter}\DIFaddend ), amplifier (JFET or OpAmp) and comparator (OpAmp) circuits. \DIFdelbegin \DIFdel{Outputs }\DIFdelend \DIFaddbegin \DIFadd{The output }\DIFaddend from pyroelectric subsystem \DIFdelbegin \DIFdel{arfiltered }\DIFdelend \DIFaddbegin \DIFadd{are filtered }\DIFaddend to remove noise, amplified to increase its magnitude and finally sent to a comparator to convert analog signals to discrete signals. This \textit{discrete signal is HIGH when there is no motion and goes HIGH$\rightarrow$LOW when motion is detected}. \DIFaddbegin \DIFadd{Systems connected to a PIR sensor such as lighting or heating use the discrete signal to regulate the illumination or temperature in a building.
}\DIFaddend 







\DIFaddbegin \begin{figure}
	\centering
    \begin{subfigure}[b]{0.4\textwidth} \begin{flushleft}
\includegraphics[width=\textwidth]{figures/platform/pir-block-diagram-2-redraw-camera.png}
            \caption{\DIFaddFL{Sensing Pipeline of a PIR Sensor}}
            \label{fig:pir_sensing_pipeline}
        \end{flushleft}
    \end{subfigure}\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lens_types/inline_lens.png}
		\caption{\DIFaddFL{Inline lens (wall-mount)}}
		\label{fig:inline_lens}
	\end{subfigure}\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lens_types/round_lens.png}
		\caption{\DIFaddFL{Round lens (ceiling-mount)}}
		\label{fig:round_lens}
	\end{subfigure}	   
	\caption{\DIFaddFL{Effect of different types of lens on the }\aout \DIFaddFL{curve, shown in green -- the inline lens type produces a single oscillation whereas a round lens type produces two oscillation per obstacle. The corresponding }\cout\DIFaddFL{, shown in blue, stays HIGH when there is no motion and goes LOW when motion is detected. }}
	\label{fig:pir_sensor_different_lens}
\end{figure}


\DIFaddend \subsection{\textbf{Analysis of Output Signals of a PIR Sensor:}}
\DIFdelbegin %DIFDELCMD < \label{subsubsec:working} 
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \label{subsec:working} 
\DIFaddend There are 2 output signals from a PIR sensor as shown in {\bfseries Fig.~\DIFdelbegin \DIFdel{\ref{fig:pir_working}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:pir_sensing_pipeline}}\DIFaddend }:
\begin{enumerate} \item \textbf{Final discrete output} of the electronic subsystem (\cout) \DIFaddbegin \DIFadd{that follows negative logic }\ie \DIFadd{stays HIGH when there is no motion and goes LOW when motion is detected}\DIFaddend . \item \textbf{Intermediate analog output} just prior to the discretization process (\aout). \end{enumerate}

\DIFdelbegin \DIFdel{We }\DIFdelend \DIFaddbegin \DIFadd{To analyze }\cout \DIFadd{and }\aout \DIFadd{during operation, we }\DIFaddend interface a PIR sensor to an Arduino microcontroller\DIFdelbegin \DIFdel{to analyze }%DIFDELCMD < \cout %%%
\DIFdel{and }%DIFDELCMD < \aout %%%
\DIFdel{during operation}\DIFdelend \DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{arduino_mega}}\hskip0pt%DIFAUXCMD
}\DIFaddend . 
{\bfseries Fig.~\DIFdelbegin \DIFdel{\ref{fig:pir_output}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:inline_lens} --~\ref{fig:round_lens}}\DIFaddend } \DIFdelbegin \DIFdel{is a plot }\DIFdelend \DIFaddbegin \DIFadd{shows plots }\DIFaddend of \aout and \cout for a period of 60 seconds, both in the presence and absence of an obstacle. The y-axis represents \DIFdelbegin \DIFdel{the }\DIFdelend voltages seen at the output and x-axis represents time. As expected, \cout, marked in blue\DIFaddbegin \DIFadd{, }\DIFaddend goes LOW when an obstacle comes into the field of view and stays HIGH otherwise. On the other hand, \aout\DIFaddbegin \DIFadd{, marked in green, }\DIFaddend measures around 1.8 V when there is no obstacle and produces \DIFdelbegin \DIFdel{an oscillation}\DIFdelend \DIFaddbegin \DIFadd{oscillation(s) }\DIFaddend when an obstacle comes into the field of view (shown magnified). 
\DIFdelbegin \DIFdel{We }\DIFdelend \DIFaddbegin \DIFadd{The nature and shape of the }\aout \DIFadd{curve also depends on the nature of lens used in the PIR sensor. Typically, an inline lens is used for the wall-mount version and a round lens is used for the ceiling-mount version. }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_different_lens}}} \DIFadd{also shows the variations in }\aout \DIFadd{between the two lens types -- }\ca \DIFadd{Inline lens has a wider curve compared to round lens and }\cb \DIFadd{Round lens has double number of oscillations of }\aout \DIFadd{curve per obstacle. We used a wall-mount PIR sensor in our experiments though our analysis, techniques and observations are equally applicable to ceiling-mount sensors. With a working background on PIR sensors, we }\DIFaddend next study the various failures in a PIR sensor and its impact on sensing physics. \DIFaddbegin \subsection{\DIFadd{Failures in PIR Sensors -- A Taxonomy}} 
\label{subsec:taxonomy} 
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{figure}[t]
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \begin{figure}\DIFaddendFL \centering
	\small
	\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.18\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.24\textwidth}
		\DIFaddendFL \centering
		\includegraphics[width=\textwidth]{figures/platform/failure_photographs/WorkingSensor-proper.jpg}
		\caption{\footnotesize Working Sensor}
		\label{fig:working}
	\end{subfigure}
	\hspace{0.10ex}\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.18\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.24\textwidth}
		\DIFaddendFL \centering
		\DIFaddbeginFL \includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassI-LensCapRemoved-annotated-jpg.jpg}
		\caption{\DIFaddFL{Lens Cap Fallen Off}}
		\label{fig:failure_photo1}
	\end{subfigure}
	\DIFaddFL{\hspace{0.10ex}
	}\begin{subfigure}[t]{0.24\textwidth}
		\centering
		\DIFaddendFL \includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassI-LensCapDislogdged-annotated-jpg.jpg}
		\caption{\footnotesize Lens Cap Dislocated}
		\label{fig:failure_photo2}
	\end{subfigure}	
	\hspace{0.10ex}
	\DIFdelbeginFL %DIFDELCMD < 

%DIFDELCMD < 	\begin{subfigure}[t]{0.18\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.24\textwidth}
		\DIFaddendFL \centering
		\DIFaddbeginFL \includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassII-LensCapDeformed-annotated-jpg.jpg}
		\caption{\DIFaddFL{Lens Cap Deformed}}
		\label{fig:failure_photo3}
	\end{subfigure}
	\begin{subfigure}[t]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassII-LensCapPunctured_new-2-annotated.png}
		\caption{\DIFaddFL{Lens Cap Punctured}}
		\label{fig:failure_photo4}
	\end{subfigure}
	\DIFaddFL{\hspace{0.1ex}
	}\begin{subfigure}[t]{0.24\textwidth}
		\centering
		\DIFaddendFL \includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassIII-LensCapCovered-annotated-jpg.jpg}
		\caption{\footnotesize Lens Cap Covered}
		\label{fig:failure_photo5}
	\end{subfigure}
	\hspace{0.1ex}\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.18\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.24\textwidth}
		\DIFaddendFL \centering
		\includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassIV-OpticalFilterDamage-annotated-jpg.jpg}
		\caption{\footnotesize Optical Filter Damaged}
		\label{fig:failure_photo6}
	\end{subfigure}	
	\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\hspace{0.1ex}
	}\begin{subfigure}[t]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/platform/failure_photographs/ClassV-ElectronicsFault-annotated-jpg.jpg}
		\caption{\DIFaddFL{Electronic Fault}}
		\label{fig:failure_photo7}
	\end{subfigure}	
\DIFaddendFL \caption{\footnotesize{Some sensors} used in our study. Note that the failures are not always visually perceivable as the sensors are typically inaccessible.}
	\label{fig:pir_sensor_failure_photographs}
\DIFdelbeginFL %DIFDELCMD < \vspace{-5pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure}





\DIFdelbegin \subsection{\DIFdel{Failures in PIR Sensors -- A Taxonomy}} 
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
%DIFDELCMD < \label{subsec:taxonomy} 
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Broadly, failures }\DIFdelend \DIFaddbegin \DIFadd{Fundamentally, failures in a PIR sensor }\DIFaddend could occur either on the lens, the pyroelectric element or the electronics. We \textit{analyze and categorize practical, common and most frequent} failures as gathered in discussions with IoT engineers and technicians who install and maintain PIR sensor deployments. 
We developed a new taxonomy for such failures, as summarized in {\bfseries Table~\ref{tab:pir_faults}} \DIFaddbegin \DIFadd{and visualized in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_failure_photographs}}}\DIFaddend . 


\DIFdelbegin %DIFDELCMD < \begin{table}[b]
%DIFDELCMD < \vspace{-\baselineskip}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \begin{wraptable}{R}{0.65\textwidth}\DIFaddendFL \centering
	\footnotesize
    \caption{{\bfseries Taxonomy of Failures} in a PIR Sensor}
    \DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD <     \begin{tabular}{p{2.5cm} p{5.25cm}}
%DIFDELCMD <     %%%
\DIFdelendFL \DIFaddbeginFL \begin{tabular}{p{2.25cm} p{6cm}}
    \DIFaddendFL \hline \textsc{\bfseries Failure} & \textsc{\bfseries Definition \& Impact}\\
    \hline\hline
    \rowcolor{gray!20} \multicolumn{2}{l}{\bfseries Lens Subsystem}\\
    Lens dislodged \newline (Class I) & Lens cap suffers partial or complete dislocation \eg physical impact with a foreign object, degradation of bonding,~\etc \\
    Lens deformed \newline (Class II) & Lens cap suffers physical damage in-place \eg deformation, puncture,~\etc \\
    Lens covered \newline (Class III) & Lens cap gets physically obstructed by foreign particles \eg dust, paper or tape \\
    \hline
    \rowcolor{gray!20} \multicolumn{2}{l}{\bfseries Pyroelectric Subsystem} \\
    Optical filter \newline damage (Class IV) & Damaged by environmental factors~\eg oil condensation\\
    \hline
    \rowcolor{gray!20} \multicolumn{2}{l}{\bfseries Electronic Subsystem} \\
    Electronic faults \newline (Class V) & Hardware failures~\eg short circuits, floating outputs~\etc \\
\hline
    \end{tabular}
    \label{tab:pir_faults}
\DIFdelbeginFL %DIFDELCMD < \end{table}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \end{wraptable}
\DIFaddend 


\subsubsection{\textbf{Failures in the lens subsystem}} The lens is geometrically constructed to precisely focus the thermal rays onto the pyroelectric element. As a result, failures affecting the optical integrity of the lens can result in loss of precision for focusing the thermal rays. We observe three types of failures here, termed Class I--III failures.

\noindent \underline{Lens dislocation (Class I):} As the lens is stuck on the sensor board with an adhesive or machined to fit over the pyroelectric element, it could get dislodged from its place or completely fall off the sensor board due to factors such as thermal expansion or physical impact. 


\noindent \underline{Lens deformation (Class II):} As the lens is made of flexible, 0.4mm thick high density plastic~\cite{fresnel}, it is susceptible to deformation by physical damage. This can alter the curvature or puncture the lens. \DIFaddbegin \DIFadd{As in Class I, the consequence of failure is imperfect capture and focusing of the thermal radiation incident on the PIR sensor.
}\DIFaddend 


\noindent \underline{Lens hindrance (Class III):} Dust particles (\eg factory floors, building construction) or common objects such as paper and plastic tape can absorb the thermal radiation resulting in reduced to no radiation falling on the pyroelectric element. The deposition of particulate matter also causes dispersion.


\DIFaddbegin \DIFadd{In summary, Classes I--III failures affect the core functionality of the lens, and results in the imperfect capture and focus of thermal radiation.
}


\DIFaddend \subsubsection{\textbf{Failures in the pyroelectric subsystem}: Optical Filter Damage \DIFaddbegin \DIFadd{(Class IV):}\DIFaddend } The optical filter and pyroelectric elements are prone to degradation with exposure to high temperature and humidity. As the optical filter is carefully calibrated to trigger in the region of human motion, it is susceptible to damage due to environmental factors such as heat sources (\eg room heaters, air-conditioners) and humidity (\eg oil condensation) as it affects the perceived temperature of the object. We name these as Class IV failures.

\subsubsection{\textbf{Failures in the Electronics}} On-board electronics consisting of filter, amplifier and comparator circuitry are prone to failures such as shorted or floating pins that we refer to as Class V failures. \DIFaddbegin \DIFadd{We only consider simple, electronic failures -- such as open, short circuits and floating inputs. Vendor-based IC testing procedures and board design process advancements have made electronic failures such as regulator, bus failures and PCB malfunctions infrequent in practice.
}\DIFaddend 






\noindent \textbf{Summary:} Failures in PIR sensors can occur in either the lens subsystem, the pyroelectric subsystem or the on-board electronics, each of which manifest differently in the underlying physics.



\DIFaddbegin \subsection{\DIFadd{Analyzing Severity of Failures -- A Quantitative Analysis}}
\label{subsec:quantify}
\DIFadd{A failure is said to impact the sensor performance if the failure results in either false detections (}{\bfseries \DIFadd{FD}}\DIFadd{) }\ie \DIFadd{false positives or missed obstacles (}{\bfseries \DIFadd{MO}}\DIFadd{) }\ie \DIFadd{false negatives in the sensor output (}\cout\DIFadd{), compared to a working sensor. As seen in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_different_lens}}}\DIFadd{, }\cout \DIFadd{is HIGH (1) when no is obstacle detected and }\cout \DIFadd{goes HIGH (1) $\rightarrow$ LOW (0) when an obstacle is detected.
}



\noindent \underline{\DIFadd{Controlled Failure Study:}} \DIFadd{To understand the impact on sensor performance, in our lab, we take 2 PIR sensors, one which is without the fault (}\working\DIFadd{) and one with the fault (}\tampered\DIFadd{). The 2 sensors are placed in as close a proximity to one another as possible such that -- }\ca \DIFadd{distance between the sensors are closer than the size of obstacle, }\cb \DIFadd{the obstacle is moved in a plane such that it comes into the detection region of both the PIR sensors simultaneously. This implies that when the obstacle (we used our palm in this case) is moved across the detection region of both PIR sensors, it grazed both at the same time, triggering the same responses from both the sensors.
}

\DIFadd{We then calculate the absolute difference ($\delta_N$) between the }\cout \DIFadd{values of the tampered sensor~}\viz  \couttampered \DIFadd{and the reference working sensor~}\viz \coutworking \DIFadd{by summing over all observations (Refer Eqn.~\ref{eqn:1}). Intuitively, a relatively low $\delta_N$ would imply that the tampered sensor is still in acceptable condition }\ie \DIFadd{the failure is not having much impact on the operation of the sensor. On the other hand, a high value of difference implies that the failure is much serious. To ease computation, we can also compute $\delta_N$ by dividing the time series into equal size chunks called }\textit{\DIFadd{windows}} \DIFadd{(W) and computing the difference between average }\cout \DIFadd{values of }\tampered \DIFadd{and }\working \DIFadd{in that window.
}

\begin{table}\small
	\centering
	\caption{\textbf{\DIFaddFL{Misclassifications}} \DIFaddFL{analysis for different failures. The numbers indicate the deviation (as defined in Eqn.~\ref{eqn:1} between $C_{out}$ values) of a faulty sensor from that of a working sensor. Higher number indicates increased degree of failure.}}
\begin{tabular}{lllll}
\hline
		\bfseries \textsc{\DIFaddFL{Failure}} & \bfseries \textsc{\DIFaddFL{Lens Dislodged}} & \bfseries \textsc{\DIFaddFL{Lens Covered}} & \bfseries \textsc{\DIFaddFL{Heat Damage}} & \bfseries \textsc{\DIFaddFL{Humidity Damage}}\\
		\hline \hline
		\rowcolor{gray!20} \DIFaddFL{$\delta_N$$^1$ $$& \DIFaddFL{35 }& \DIFaddFL{48 }& \DIFaddFL{29 }& \DIFaddFL{48 }\\
		\DIFaddFL{$\delta_N}^2$ }& \DIFaddFL{69 }& \DIFaddFL{94  }& \DIFaddFL{53 }& \DIFaddFL{87 }\\
		\hline 
	\end{tabular}
	\label{tbl:fault_degree}
\DIFaddFL{\quad }\raggedright
	\DIFaddFL{$^1$ 6 hour run, $^2$ 12 hour run
}\end{table} 

\textbf{\DIFadd{Table~\ref{tbl:fault_degree}}} \DIFadd{summarizes $\delta_N$ for a few types of failures as observed over 6-hour and 12-hour runs deployed in the elevator of our building. The numbers in the column represent deviation or misclassifications ($\delta_N$)~}\ie \DIFadd{the number of false detections (both false positives and false negatives) by the faulty sensor calculated using }{\bfseries \DIFadd{Eqn.~\ref{eqn:1}}}\DIFadd{.
We used a window size, $W$ = 1024 samples, which comes to a window of time duration slightly over 51 seconds at a sampling rate of 20 Hz.
In our case, the lens covered failure (8 failures per hour) is more pernicious than lens having fallen off (6 failures per hour).
}


\begin{equation}
	{\DIFadd{\tikzmarknode{d}{\highlight{blue}{$\delta_N$}}}} \DIFadd{= \underset{windows}{\sum} 
	\left| }{\DIFadd{\tikzmarknode{t}{\highlight{red}{$C_{\text{out,tampered}}$}}}} \DIFadd{- }{\DIFadd{\tikzmarknode{w}{\highlight{green}{$C_{\text{out, working}}$}}}}\DIFadd{\right|,
	\label{eqn:1}
	\begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
\path (d.south) ++ (0,-0.6em) node[anchor=north east,color=blue!67] (scalep){\textbf{misclassifications}};
		\draw [color=blue!57](d.south) |- ([xshift=0.3ex,color=red]scalep.south west);
	\end{tikzpicture}
	\begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
\path (t.north) ++ (0,0.6em) node[anchor=south east,color=red!67] (scalep){\textbf{tampered}};
		\draw [color=red!57](t.north) |- ([xshift=-12ex,color=red]scalep.south east);
	\end{tikzpicture}
	\begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
\path (w.north) ++ (0,0.6em) node[anchor=south west,color=teal] (scalep){\textbf{working}};
		\draw [color=teal!57](w.north) |- ([xshift=-0.3ex,color=green]scalep.south east);
	\end{tikzpicture}
}\end{equation}\\






\noindent \textbf{\DIFadd{Summary:}} \DIFadd{Quantifying the impact of a failure gives hints on how pernicious specific failures are }\textit{\DIFadd{once they have been detected}}\DIFadd{.
}




\DIFaddend \begin{figure}[b]
	\centering
	\DIFdelbeginFL %DIFDELCMD < \vspace{-2\baselineskip}
%DIFDELCMD < 	\begin{subfigure}[b]{0.24\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[b]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale=0.37, height=0.95in]{figures/platform/controlled_setup-2.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale=0.6, height=1.3in]{figures/platform/controlled_setup-2.png}
		\DIFaddendFL \caption{Controlled Setup}
		\label{fig:pir_sensor_controlled}
	\end{subfigure}\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.23\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classI/classI_compared-again.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classI/classI_compared-again.png}
		\DIFaddendFL \caption{Class I Fault}
		\label{fig:pir_sensor_controlled_a}
	\end{subfigure}\DIFdelbeginFL %DIFDELCMD < 

%DIFDELCMD < 	\begin{subfigure}[t]{0.24\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classII/classII_compared.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classII/classII_compared.png}
		\DIFaddendFL \caption{Class II Fault}
		\label{fig:pir_sensor_controlled_b}
	\end{subfigure}\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.24\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \\\begin{subfigure}[t]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classIII/classIII_compared.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classIII/classIII_compared.png}
		\DIFaddendFL \caption{Class III Fault}
		\label{fig:pir_sensor_controlled_c}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < 

%DIFDELCMD < 	\begin{subfigure}[t]{0.24\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classIV/classIV_summary.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classIV/classIV_summary.png}
		\DIFaddendFL \caption{Class IV Fault}
		\label{fig:pir_sensor_controlled_d}
	\end{subfigure}\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.24\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.3\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classV/classV_summary.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classV/classV_summary.png}
		\DIFaddendFL \caption{Class V Fault}
		\label{fig:pir_sensor_controlled_e}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \caption{(\ref{fig:pir_sensor_controlled_a} - \ref{fig:pir_sensor_controlled_e}) \footnotesize{\aout waveforms for sensor faults of Classes I--V}. Note that in Class I -- III faults, despite the obstacle still being detected, \aout provides indication of underlying abnormalities in the sensor.
}
	\label{fig:pir_sensor_controlled_classI-V}
\DIFdelbeginFL %DIFDELCMD < \vspace{-\baselineskip}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure}






%
 \DIFdelbegin %DIFDELCMD < \vspace{-6pt}
%DIFDELCMD < %%%
\DIFdelend \section{Characterizing Failures using an Intrinsic Signal}
\DIFdelbegin %DIFDELCMD < \label{subsec:controlled}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \label{sec:aout_char}
\DIFaddend Our hypothesis is that the intermediate analog signal (\aout) from the pyroelectric element captures information that is critical to detect various failures. 
We now describe how this intrinsic signal and its underlying physics is useful to characterize failures.

\subsection{\aout signal to detect failures in PIR sensors}
\DIFaddbegin \label{subsec:controlled}
\DIFaddend As described in \DIFdelbegin \DIFdel{Section~\ref{subsubsec:working}}\DIFdelend \DIFaddbegin \DIFadd{\S~\ref{subsec:working}}\DIFaddend , there are two output signals from a PIR \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{sensor,~}\DIFaddend \viz \aout and \cout. 
The latter is a discrete signal typically used for detecting \DIFdelbegin \DIFdel{human }\DIFdelend \DIFaddbegin \DIFadd{obstacle }\DIFaddend presence and is derived from \aout.
To show the utility of \aout, we conducted numerous controlled experiments where we manually injected commonly seen faults ({\bfseries Fig.~\ref{fig:pir_sensor_failure_photographs}}). 







\DIFdelbegin \DIFdel{We }\DIFdelend \DIFaddbegin \DIFadd{Using the setup from }{\DIFadd{\S\ref{subsec:quantify}}}\DIFadd{, we }\DIFaddend co-located \DIFdelbegin \DIFdel{two sensors: }%DIFDELCMD < \ci %%%
\DIFdel{a tampered sensor (}%DIFDELCMD < \tampered%%%
\DIFdel{) containing the failure and }%DIFDELCMD < \cii %%%
\DIFdel{a working sensor (}%DIFDELCMD < \working%%%
\DIFdel{) such that: }%DIFDELCMD < \ca %%%
\DIFdel{the distance between the sensors is closer than the size of the obstacle, }%DIFDELCMD < \cb %%%
\DIFdel{the obstacle is moved in a plane such that it comes into the detection region of both sensors simultaneously and }%DIFDELCMD < \cc %%%
\DIFdel{the obstacle is larger than the distance between the }\DIFdelend two sensors, \DIFdelbegin \DIFdel{allowing it to be incident on both the sensors simultaneously. Thus, we expect the same output from both }\DIFdelend \tampered and \working\DIFdelbegin \DIFdel{. We }\DIFdelend \DIFaddbegin \DIFadd{, where we }\DIFaddend change the \tampered sensor to test different types of failures described in \S\ref{subsec:taxonomy}. \DIFaddbegin \DIFadd{While in \S\ref{subsec:quantify}, we focused on }\cout \DIFadd{to study sensor performance during failure, in this experiment we additionally analyze }\aout \DIFadd{to get an understanding of the }\textit{\DIFadd{sensor physics}} \DIFadd{during failure.
}\DIFaddend 


We note the output signals (\ie \aout and \cout) \DIFaddbegin \DIFadd{from }\tampered \DIFaddend in every failure scenario and compare it with \DIFdelbegin \DIFdel{a working sensor }\DIFdelend \DIFaddbegin \DIFadd{that from }\working \DIFaddend \emph{to understand the impact of failure on \DIFdelbegin \DIFdel{the }\DIFdelend physics of the sensors}. Each experiment described below lasted for 15 minutes, \DIFdelbegin \DIFdel{when }\DIFdelend \DIFaddbegin \DIFadd{where }\DIFaddend the obstacle (our palm in this case) was moved into the region of detection once every minute. We plot \aout for both a working sensor and every type of faulty sensor in {\bfseries Figs.~\ref{fig:pir_sensor_controlled_a} --~\ref{fig:pir_sensor_controlled_e}}. The y-axis \DIFdelbegin \DIFdel{plots the }\DIFdelend \DIFaddbegin \DIFadd{represents }\DIFaddend voltage output of \aout and \DIFdelbegin \DIFdel{the }\DIFdelend x-axis \DIFdelbegin \DIFdel{is }\DIFdelend \DIFaddbegin \DIFadd{represents }\DIFaddend time. For \DIFdelbegin \DIFdel{a working sensor }\DIFdelend \DIFaddbegin \DIFadd{the working sensor }\working\DIFaddend , we expect a spike in \aout once every 60 seconds denoting motion of the palm. \DIFaddbegin \DIFadd{Let us now study the nature of }\aout \DIFadd{in each fault.
}\DIFaddend 

\textbf{Lens dislocation (Class I) faults.} The absence/dislocation of the lens causes imperfect focus of \DIFdelbegin \DIFdel{the }\DIFdelend thermal radiation resulting in \DIFdelbegin \DIFdel{the }\DIFdelend some residual output at the pyroelectric element even when there is no obstacle present. The impact of a Class I fault on \aout is shown in \textbf{Fig.~\ref{fig:pir_sensor_controlled_a}}. 
We can see that both the tampered and working sensors are still able to detect the obstacle (as shown by the 15 vertical spikes of \aout). However, when the obstacle is not present, we observe that the noise of \aout is much higher with a Class I fault as compared to a working sensor. Thus, it is important to look beyond just \cout signal to identify such failures.

\textbf{Lens deformation (Class II) faults.} Class II faults can potentially lead to missing \DIFdelbegin \DIFdel{the obstacles in }\DIFdelend \DIFaddbegin \DIFadd{obstacles at }\DIFaddend the periphery of the field of view due to deformation or loss of material integrity (\eg puncture). 
\textbf{Fig.~\ref{fig:pir_sensor_controlled_b}} shows the \aout for a sensor with a Class II fault. The amplitude of \aout at the times of obstacle detection is lower when compared to a working sensor. This is expected since the damage to \DIFdelbegin \DIFdel{the }\DIFdelend lens leads to reduced thermal radiation incident on the pyroelectric subsystem. In general, Class II faults creates blind spots in the lens aperture that \DIFdelbegin \DIFdel{reduce }\DIFdelend \DIFaddbegin \DIFadd{can reduce amplitude of }\DIFaddend the \aout \DIFdelbegin \DIFdel{amplitude}\DIFdelend \DIFaddbegin \DIFadd{signal}\DIFaddend . 



\textbf{Lens hindrance (Class III) faults} are caused due to foreign particles entering the lens that compromise its optical capability, thereby affecting the intensity and angle of radiation incident on the pyroelectric element. 
We induce such faults by depositing some dust on the lens.
\textbf{Fig.~\ref{fig:pir_sensor_controlled_c}} shows that the amplitude of \aout varies at each of the detection points. The variation depended on the amount of dust with respect to the orientation of the obstacle. Though the obstacle was still being detected, we note that with increased dust deposition, the amplitude of \aout can fall below the comparator threshold required to capture the obstacle\DIFdelbegin \DIFdel{resulting in failure}\DIFdelend \DIFaddbegin \DIFadd{, resulting in a missed obstacle }\ie \DIFadd{false negative}\DIFaddend . 







\textbf{Failure in pyroelectric components (Class IV).} Class IV faults happen when the optical filter on the pyroelectric element comes in contact with contaminants such as oil, mist or other smudge, \DIFdelbegin \DIFdel{it can lead to }\DIFdelend \DIFaddbegin \DIFadd{resulting in }\DIFaddend potentially missing obstacles. High temperatures can also cause expansion of the optical filter that can also result in failures. 
We induce Class IV faults by spraying some oil on the optical filter. We observe in {\bfseries Fig~\ref{fig:pir_sensor_controlled_d}} that \aout has significantly attenuated spikes at each of the points that correspond to obstacle motion, but the spikes are not high enough to cause \cout to drop \DIFdelbegin \DIFdel{to }\DIFdelend LOW. This results in the obstacle to be missed completely. \DIFaddbegin \DIFadd{A similar effect is observed when the optical filter is exposed to heat as it affects the temperature variation needed for pyroelectric effect.
}\DIFaddend 



\textbf{Failure in electronics (Class V) faults.} \DIFdelbegin \DIFdel{These are usually }\DIFdelend \DIFaddbegin \DIFadd{Class V faults are typically }\DIFaddend electronic faults such as short \DIFdelbegin \DIFdel{circuits }\DIFdelend or open circuits. They can cause the \aout or \cout values to be `stuck' at certain anomalous value such as HIGH (3.3 V) or LOW (0 V). As a result, these failures can cause the obstacle to be completely missed\DIFdelbegin \DIFdel{as seen }\DIFdelend \DIFaddbegin \DIFadd{. This is observed }\DIFaddend in {\bfseries Fig.~\ref{fig:pir_sensor_controlled_e}}\DIFdelbegin \DIFdel{. The }\DIFdelend \DIFaddbegin \DIFadd{, where }\DIFaddend \aout \DIFaddbegin \DIFadd{is shorted to the power supply, resulting in }\cout \DIFadd{following }\aout \DIFadd{and remaining HIGH. Consequently, the }\aout \DIFaddend waveform here is a flat, horizontal line and lacks oscillations. 


\DIFaddbegin \noindent \DIFaddend \textbf{\DIFdelbegin \DIFdel{Insights into underlying physics}\DIFdelend \DIFaddbegin \DIFadd{Summary:}\DIFaddend } The core insight here is that \aout can shed light on the physical and electrical operating conditions of a PIR sensor as opposed to the mere boolean occupancy indicated by \cout. Thus, being able to snoop in on \aout can capture the interaction of IR radiation on the different sensor subsystems. 




\DIFaddbegin \subsection{\DIFadd{Analysis of }\aout \DIFadd{during partial failures and gradual degradation}} \label{subsec:incremental_dust}\DIFadd{In \S\ref{subsec:controlled}, we observed the impact of failures in PIR sensors, from classes I through V on nature of }\aout \DIFadd{and }\cout\DIFadd{. While we developed a structural taxonomy in \S\ref{subsec:taxonomy}, we note that failures need not be binary in nature, and there can be partial failures. Consequently, there are variations in each of the failure classes. For example, in Class III faults, the gradual build of dust can lead to degradation of sensing performance. }\begin{figure*}[htbp]
	\centering
\begin{subfigure}[t]{0.23\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/gradual_degradation_dust/Stage0.png}
		\caption{\DIFaddFL{Clean Sensor : Working}}
		\label{fig:pir_sensor_classIII_fault_good}
	\end{subfigure}
	\DIFaddFL{\hspace{1ex}
	}\begin{subfigure}[t]{0.23\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/gradual_degradation_dust/Stage1.png}
		\caption{\DIFaddFL{Degraded Sensor : Still Working}}
		\label{fig:pir_sensor_classIII_fault_bad1}
	\end{subfigure}	
	\DIFaddFL{\hspace{1ex}
	}\begin{subfigure}[t]{0.23\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/gradual_degradation_dust/Stage2.png}
		\caption{\DIFaddFL{Degraded Sensor : 1/5 miss}}
		\label{fig:pir_sensor_classIII_fault_bad2}
	\end{subfigure}		
	\DIFaddFL{\hspace{1ex}
	}\begin{subfigure}[t]{0.23\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/gradual_degradation_dust/Stage3.png}
		\caption{\DIFaddFL{Failed Sensor : 5/5 miss}}
		\label{fig:pir_sensor_classIII_fault_bad3}
	\end{subfigure}	
	\caption{\DIFaddFL{Dust gradually building up in different degrees causing Class III faults -- }\ca \DIFaddFL{is a clean sensor and dust gradually builds up }\cb \DIFaddFL{-- }\cd \DIFaddFL{at which stops detecting obstacles.}}
	\label{fig:pir_sensor_classIII_fault_gradual}
\end{figure*}

\DIFadd{To study the effect of gradual failures occurring in Class III, we divided a spatula of chalk-dust (approximately one-fourth of a teaspoon) and measured the effect of dust on response of the sensor. At every stage of study, we incrementally added dust and measured performance by plotting the two output signals }\cout \DIFadd{and }\aout \DIFadd{in the presence of an obstacle. The experiment is summarized in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_classIII_fault_gradual}}}\DIFadd{. With increasing amount of dust being deposited, we see that the final discrete output misses the obstacle on occasion while detecting it sometimes. As a result, information about the dust deposition is lost at times from the final discrete output, }\cout\DIFadd{. }\textit{\DIFadd{Note that however, the intermediate analog output, }\aout \DIFadd{is able to capture information regarding the deposition of dust and by showing the degradation of sensing performance via its reduced amplitude.}} \DIFadd{Consequently, the obstacle detection process works till a reduced amplitude of }\aout \DIFadd{(}{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_classIII_fault_bad1}}}\DIFadd{), below which the sensor begins missing some obstacle instances. This process aggravates as more dust is accumulated on the sensor until a stage when there is a complete failure (}{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_classIII_fault_bad3}}}\DIFadd{).
}

\noindent \textbf{\DIFadd{Summary:}} \DIFadd{The key observation here is that capturing the physics of sensing via }\aout \DIFadd{helps glean valuable insights into even partial failures, which is completely absent in the }\cout \DIFadd{signal.
}


\subsection{\DIFadd{Analysis of }\aout \DIFadd{during known quiet times}} \label{subsec:aout_quiet_times} \DIFadd{We draw some intuition on the behavior of }\aout \DIFadd{during known times of no occupancy, }\eg \DIFadd{post business hours in case of office buildings. The intuition stems from the arrangement of pyroelectric elements and its interplay with the lens subsystem. In a working sensor, we observe that due to the precise geometric arrangement of lens and pyroelectric elements, when there is no obstacle, the thermal radiation from the environment falls equally on the two pyroelectric elements, causing it to cancel out and leave very little noise at the output of pyroelectric subsystem. However, when the lens is covered by a foreign substance (}\ie \DIFadd{Class III fault), some of the thermal radiation is absorbed by the substance, before falling onto the pyroelectic elements. This results in a much lower noise at the output of pyroelectric subsystem. Alternately, if the lens is dislodged (}\ie \DIFadd{Class I fault), the two pyroelectric elements are not perfectly matched in differential configuration, which leads to higher noise at output of the pyroelectric subsystem. We observe this noise by measuring the }\textit{\DIFadd{noise floor}} \DIFadd{in the variance of }\aout \DIFadd{signal, during times of no obstacle.
}

\DIFadd{Thus, we note that variance of }\aout \DIFadd{during a period with no occupancy can be used to get hints on Class I (lens dislodged) and Class III faults (lens covered). In particular, compared to a working sensor where the lens is mounted correctly, we expect a drop in variance when the lens is covered and a rise in variance when the lens is dislodged. In other words, $\sigma$(}\aout\DIFadd{)$|_{Class\ III}$ $\leq$ $\sigma$(}\aout\DIFadd{)$|_{Working}$ $\leq$ $\sigma$(}\aout\DIFadd{)$|_{Class\ I}$, where $\sigma$(}\aout\DIFadd{)$|_{X}$ denotes the variance of }\aout \DIFadd{under scenario X. We can use this idea to develop a preliminary fault detection algorithm that can be used to screen for lens faults (Class I and III). This requires computing two variance-based thresholds ($T_L$, $T_H$) to deduce status of the lens.
}

\DIFadd{However, we note that using the variance of }\aout \DIFadd{is not viable in all practical conditions. In particular, using this method works only during }\textit{\DIFadd{known quiet}} \DIFadd{times }\ie \DIFadd{in the known absence of occupancy which can be a }\textit{\DIFadd{disadvantage}} \DIFadd{for some deployments. As a result, this approach is suited for preliminary sensor health checks outside office or regular business hours of operation such as weekends. 
}

\begin{wrapfigure}{L}{10cm}\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classIII/Aout_normal_vs_plastic.png}
		\caption{\DIFadd{Plastic}}
		\label{fig:pir_sensor_classIII_fault_plastic_tape}
	\end{subfigure}
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classIII/Cout_Aout_Paper.png}
		\caption{\DIFadd{Paper}}
		\label{fig:pir_sensor_classIII_fault_paper}
	\end{subfigure}	
	\caption{\DIFadd{Effect of different foreign particles producing Class III faults of different degree -- the figures show that when the lens is obstructed with foreign particles like plastic tape and paper, it could result in complete failure.}}
	\label{fig:pir_sensor_different_foreign_particles}
\end{wrapfigure}

\subsection{\DIFadd{Analysis of different types of foreign particles}} \label{subsec:foreign_additional}\DIFadd{Different materials have distinct thermal characteristics and thus affect the }\aout \DIFadd{response differently in case of Class III faults. Stated alternately, the amplitude shaping of }\aout \DIFadd{varies depends on the material and its quantity. There are 3 kinds of foreign particles we study in our setup -- }\ca \DIFadd{paper, }\cb \DIFadd{plastic tape and }\cc \DIFadd{dust. We saw in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_controlled_c}}} \DIFadd{how deposition of dust can compromise with the }\aout \DIFadd{responses. }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_different_foreign_particles}}} \DIFadd{shows Class III fault scenarios repeated with plastic tape and paper. In each of these runs, a normal sensor (represented in the blue curve in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_classIII_fault_plastic_tape}}}\DIFadd{) detects obstacles as demonstrated by the }\aout \DIFadd{variation, whereas foreign particles such as paper and plastic tape can lead to a }\textit{\DIFadd{complete failure}} \DIFadd{of the PIR sensor.
}




\DIFaddend \begin{comment}
\textbf{Note:} The variance of \aout during a period with no obstacle can be used to get hints on Class I faults (lens dislodged) and Class III faults (lens covered). In particular, compared to a working sensor where the lens is mounted correctly, we observe a drop in variance when the lens is covered and a rise in variance when the lens has fallen. In other words, $\sigma$(\aout)$|_{Class\ III}$ $\leq$ $\sigma$(\aout)$|_{Working}$ $\leq$ $\sigma$(\aout)$|_{Class\ I}$, where $\sigma$(\aout)$|_{X}$ denotes the variance of \aout under scenario X. We extend this to develop a preliminary fault detection algorithm that can be used to detect Class I and Class III faults. This requires the computation of two variance-based thresholds ($T_L$, $T_H$) to deduce the status of the lens. 

However, we note that using the variance of \aout is not viable in all practical conditions. In particular, this method works only during \textit{quiet} times \ie in the absence of an obstacle which is a \textit{disadvantage}. As a result, this approach is suited for outside office or regular business hours of operation such as weekends. Therefore, we need to perform additional characterization of the \aout output signal to reason about the failures.
\end{comment}




\begin{comment}
\subsection{Time Domain Characterization} We ask ourselves the question -- `What can we learn from only the time domain representation of \aout ?' Recall from {\bfseries Fig.~\ref{fig:pir_sensor_controlled_a}}, that we observed the variance of \aout during a period of no obstacle is a key indicator of lens fault\ie \ca lens being covered (say due to a foreign particle) or \cb lens falls off completely (say due to imperfect bonding). We compare this with the case where lens cap is mounted correctly. 



We deployed three sensors over lunchtime in an office cafeteria : \ci a working sensor, \cii a sensor with lens covered with tape, and \ciii a sensor with lens fallen (removed). This time-domain behavior of \aout in these cases is summarized in {\bfseries Fig.~\ref{fig:variance_cap_cases}}.  We observe a drop in variance when the lens is covered and a rise in variance if the lens falls off. In other words, $\sigma$(\aout) $|_{Covered}$ $\leq$ $\sigma$(\aout) $|_{Working}$ $\leq$ $\sigma$(\aout) $|_{No\ Lens}$, where $\sigma$(\aout) denotes the variance of \aout.

Extending this we develop a threshold-based fault detection algorithm (Algorithm~\ref{alg:fault_detection}) that can be used to detect simple faults in lens. This requires the computation of variance-based thresholds ($T_L$, $T_H$) to find the status of the lens.

Despite the theoretical correctness of this time-domain approach, we note that using variance of \aout is not viable in all practical conditions. In particular, it has the \textit{disadvantage} that it works only during \textit{quiet} times \ie requiring the absence of an obstacle. Thus, this approach is suited for outside office or regular business hours of operation such as weekends.

Consequently, we look for other approaches of characterizing the \aout waveform.



\end{comment}



\begin{figure}\centering
\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.33\textwidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth, height =0.8in]{figures/2-PIR-Fault/normal-classI/class1_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classI/class1_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{Class I fault}
		\label{fig:classI_fault_freq}
	\end{subfigure}
	\DIFdelbeginFL \DIFdelFL{\hspace{1ex}
	}%DIFDELCMD < \begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.33\textwidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth, height =0.8in]{figures/2-PIR-Fault/normal-classII-deformed/class2_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classII-deformed/class2_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{Class II fault}
		\label{fig:classII_fault_freq}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < \\
%DIFDELCMD < 	\begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.325\textwidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth, height =0.8in]{figures/2-PIR-Fault/normal-classIII/class3_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/2-PIR-Fault/normal-classIII/class3_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{Class III fault}
		\label{fig:classIII_fault_freq}
	\end{subfigure}\DIFdelbeginFL \DIFdelFL{\hspace{1ex}
	}%DIFDELCMD < \begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \\
	\begin{subfigure}[t]{0.33\linewidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth, height =0.8in]{figures/2-PIR-Fault/normal-classIV/class4_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classIV/class4_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{Class IV fault}
		\label{fig:classIV_fault_freq}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < \\
%DIFDELCMD < 	\begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.33\linewidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth, height =0.8in]{figures/2-PIR-Fault/normal-classV/class5_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-classV/class5_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{Class V fault}
		\label{fig:classV_fault_freq}
	\end{subfigure}
	\DIFdelbeginFL \DIFdelFL{\hspace{1ex}
	}%DIFDELCMD < \begin{subfigure}[t]{0.48\linewidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.325\linewidth}
		\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\linewidth,  height =0.8in]{figures/2-PIR-Fault/normal-normal/normal_normal_fft_coloradj_small_edited_camera_ready.png}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\linewidth]{figures/2-PIR-Fault/normal-normal/normal_normal_fft_coloradj_small_edited_camera_ready.png}
		\DIFaddendFL \caption{\textbf{Comparing} \aout of two working sensors}
		\label{fig:normal_normal_freq}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \caption{\footnotesize{Frequency Domain Representations} of \aout under different faults in a PIR sensor. Only frequencies upto 10 Hz are shown \DIFdelbeginFL \DIFdelFL{because the human motion range }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{as }\DIFaddendFL most PIR sensors detect \DIFdelbeginFL \DIFdelFL{are in that range}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{human motion within 10 Hz}\DIFaddendFL .}
	\label{fig:classI-V_fault_freq}	
\DIFdelbeginFL %DIFDELCMD < \vspace{-2\baselineskip}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure}
\DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \subsection{Frequency Domain Characterization} \label{subsec:freq_char} \DIFdelbegin \DIFdel{Till now we }\DIFdelend \DIFaddbegin \DIFadd{We }\DIFaddend have showed \aout signal \DIFdelbegin \DIFdel{can be used to detect }\DIFdelend \DIFaddbegin \DIFadd{has hints about }\DIFaddend various failure scenarios. \DIFdelbegin \DIFdel{We transform }\DIFdelend \DIFaddbegin \DIFadd{To get additional insights, we transform the }\DIFaddend time domain \aout signal into \DIFdelbegin \DIFdel{the }\DIFdelend frequency domain using \DIFaddbegin \DIFadd{the }\DIFaddend Fast Fourier transform (FFT) to derive robust features. FFT offers high resolution in the frequency domain and deconstructs the frequencies and harmonics present in a signal. \DIFaddbegin \DIFadd{Frequency domain representations have been used to characterize human activities using smartphone sensors and perform vibration screening for faults both in aircraft and railway lines~\mbox{%DIFAUXCMD
\cite{anguita2013public, HanlyWhy}}\hskip0pt%DIFAUXCMD
. 
}\DIFaddend 

We plot the FFT representations of \aout corresponding to different faults in {\bfseries Figs.~\ref{fig:classI_fault_freq}--~\ref{fig:classV_fault_freq}} as compared to a working sensor, all under the presence of an obstacle. The y-axis plots \DIFdelbegin \DIFdel{the }\DIFdelend magnitude of FFT coefficients and the x-axis plots frequencies in the human range of motion (0 -- 10 Hz). In case of a working sensor, we observe 2 big peaks and additional peripheral frequencies up to 4 Hz. \DIFdelbegin \DIFdel{The frequency spectrum depends }\DIFdelend \DIFaddbegin \DIFadd{We now study how the frequency spectrum varies depending }\DIFaddend on the type of faults.



\textbf{Class I faults}  We observe in \textbf{Fig.~\ref{fig:classI_fault_freq}} that a dislodged lens cap (either partial or complete) leads to reduced information capture (lower bandwidth) and as a result, the sensitivity in the periphery of the sensors reduces. Note that there is just a single prominent peak in the faulty sensor (at a slightly lower frequency when compared to the normal sensor) that corresponds to the obstacle being perfectly aligned with the center of sensor as it passes. The magnitude reduces sharply as it moves away from the center of the sensor. 

\textbf{Class II faults} \textbf{Fig.~\ref{fig:classII_fault_freq}} plots the FFT for a sensor with deformed lens cap. 
We note that Class II \DIFdelbegin \DIFdel{failures }\DIFdelend \DIFaddbegin \DIFadd{faults }\DIFaddend lead to significantly suppressed primary peaks (approx. 10 db). In addition, the peripheral frequencies are attenuated as observed in Class I. \DIFaddbegin \DIFadd{These faults can manifest itself in reduced sensor performance as some of the detection region become }\textit{\DIFadd{blind spots}} \DIFadd{for the sensor.
}\DIFaddend 



\textbf{Class III faults} due to accumulation of foreign particles in the lens, lead to reduced sharpness of frequencies.
We observe in \textbf{Fig.~\ref{fig:classIII_fault_freq}} that the degradation starts with damping of the higher frequencies. As the amount of dust increases, we \DIFdelbegin \DIFdel{observed }\DIFdelend \DIFaddbegin \DIFadd{observe }\DIFaddend the frequencies getting increasingly damped until the object detection starts failing.


\textbf{Class IV faults}
We observe in \textbf{Fig.~\ref{fig:classIV_fault_freq}} that the frequencies present in the output are heavily suppressed resulting in missed obstacle detection. This is expected since the optical filter plays a major role in filtering out the non-human range frequencies from the thermal radiation and only passing through the frequencies corresponding to the human range. The presence of oil condensation or heat sinks causes absorption of the thermal radiation resulting in insufficient heat to cause pyroelectric effect. 

\textbf{Class V faults} such as open and short circuits are easy to detect due to the absence of any prominent frequencies. Consequently, \aout is \textit{stuck at} a value leading to only dc frequencies being present in the output. This result is observed in {\bfseries Fig.~\ref{fig:classV_fault_freq}}, where the \cout and \aout pins are shorted on the board. 

\noindent \textbf{Summary:} Frequencies present in FFT representations of \aout provide hints regarding status (\ie working/failed) of PIR sensors.














 \DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \section{Fault Detection and Diagnosis} 
\label{sec:system_char}



In \S\DIFdelbegin \DIFdel{\ref{subsec:controlled}}\DIFdelend \DIFaddbegin \DIFadd{\ref{sec:aout_char}}\DIFaddend , we analyzed the impact of failures on the characteristics of the \aout output signal in both time domain and in frequency domain using FFT. \DIFdelbegin \DIFdel{In \S\ref{subsec:learnability}}\DIFdelend \DIFaddbegin \DIFadd{We now investigate if the characteristics of }\aout \DIFadd{contain behavior that is amenable to learning }\ie \DIFadd{if there are features to be learnt. First, we analyze the learnability of the fault detection and diagnosis problem in \S\ref{subsec:learnability}. During this}\DIFaddend , we show that in every type of failure, there exists information about the failure and quantify the difference in physics captured by FFT coefficients using a K-S statistic test~\cite{massey1951kolmogorov}.

\DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \begin{wraptable}{L}{0.4\textwidth}
\setlength\tabcolsep{2.5pt}
\centering
\caption{{\DIFadd{K-S Statistic Results}}\DIFadd{: FC1 -- FC5 : Failure Class I -- V. W : working sensor.}}
\begin{tabular}{l c c c c c c}
			\hline
			\textbf{\DIFadd{Failure}} & \textbf{\DIFadd{FC1}} & \textbf{\DIFadd{FC2}} & \textbf{\DIFadd{FC3}} & \textbf{\DIFadd{FC4}} & \textbf{\DIFadd{FC5}} & \textbf{\DIFadd{W}} \\
			\hline \hline
			\DIFadd{K-S Test }& \DIFadd{0.41 }& \DIFadd{0.33 }& \DIFadd{0.49 }& \DIFadd{0.65 }& \DIFadd{0.95 }& \DIFadd{0.09 }\\
			\hline 
		\end{tabular}
\label{tbl:ks_test_results}
\end{wraptable}

\DIFaddend \subsection{Learnability of the Analysis}
\label{subsec:learnability}

We performed a 2-sample Kolmogorov–Smirnov (K-S) statistic test~\cite{massey1951kolmogorov} to validate our hypothesis that the \aout distributions from both working and failed sensors are different.  We performed the tests at a significance level ($\alpha$) = 0.05, that results in a K-S statistic threshold of 0.1 -- a standard threshold for checking if sample differences in two distributions imply difference in population. {\bfseries Table~\ref{tbl:ks_test_results}} shows the K-S statistic (\DIFdelbegin \DIFdel{kstest2 }\DIFdelend \DIFaddbegin \texttt{\DIFadd{kstest2}} \DIFaddend in Matlab~\cite{mathworks2015kstest2}) computed for each class of failure relative to a working sensor in columns FC1 -- FC5. We make the following observations :

\noindent \textbf{Failed sensors have different frequency characteristics compared to a working sensor:} Each failure class FC1 --- FC5 has a K-S statistic value > 0.1 when compared to a working sensor (W), indicating that the distributions of faulty and working sensors \DIFdelbegin \DIFdel{dffer}\DIFdelend \DIFaddbegin \DIFadd{differ}\DIFaddend . 

\noindent \textbf{The worse the failure, higher the K-S statistic:} A sensor with oil condensation on the lens (C4) (a more pernicious fault leading to missed obstacles) resulted in a K-S statistic of 0.65 compared to 0.33 for a sensor with lens deformation (C2) (milder fault resulting in some blind spots). The K-S statistic \DIFdelbegin \DIFdel{computes }\DIFdelend \DIFaddbegin \DIFadd{captures }\DIFaddend the divergence between \DIFdelbegin \DIFdel{the }\DIFdelend physics of failed and working sensors.


\noindent \textbf{Working sensors have similar characteristics:} We performed a sanity check between distributions of multiple working sensors and noticed the consistency among them in the frequency domain. Computing the K-S statistic resulted in a value below the 0.1 threshold implying similar physics as seen in {\bfseries Fig.~\ref{fig:normal_normal_freq}}.





\DIFdelbegin %DIFDELCMD < \begin{table}
%DIFDELCMD <   	\vspace{-\baselineskip}
%DIFDELCMD < \setlength\tabcolsep{1.45pt}
%DIFDELCMD < \centering
%DIFDELCMD <     \small
%DIFDELCMD < %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{K-S Statistic Results}%%%
\DIFdelFL{: FC1-FC5 : failure class I-V. W : working sensor.}}
%DIFAUXCMD
%DIFDELCMD < \vspace{-10pt}
%DIFDELCMD <     \begin{tabular}{l c c c c c c}
%DIFDELCMD <         \hline
%DIFDELCMD <         %%%
\textbf{\DIFdelFL{Failure}} %DIFAUXCMD
%DIFDELCMD < & %%%
\textbf{\DIFdelFL{FC1}} %DIFAUXCMD
%DIFDELCMD < & %%%
\textbf{\DIFdelFL{FC2}} %DIFAUXCMD
%DIFDELCMD < & %%%
\textbf{\DIFdelFL{FC3}} %DIFAUXCMD
%DIFDELCMD < & %%%
\textbf{\DIFdelFL{FC4}} %DIFAUXCMD
%DIFDELCMD < & %%%
\textbf{\DIFdelFL{FC5}} %DIFAUXCMD
%DIFDELCMD < & %%%
\DIFdelendFL \DIFaddbeginFL \noindent \DIFaddendFL \textbf{\DIFdelbeginFL \DIFdelFL{W}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{Summary:}\DIFaddendFL } \DIFdelbeginFL %DIFDELCMD < \\
%DIFDELCMD <         \hline \hline
%DIFDELCMD <         %%%
\DIFdelendFL K-S \DIFdelbeginFL \DIFdelFL{Test }%DIFDELCMD < & %%%
\DIFdelFL{0.41 }%DIFDELCMD < & %%%
\DIFdelFL{0.33 }%DIFDELCMD < & %%%
\DIFdelFL{0.49 }%DIFDELCMD < & %%%
\DIFdelFL{0.65 }%DIFDELCMD < & %%%
\DIFdelFL{0.95 }%DIFDELCMD < & %%%
\DIFdelFL{0.09 }%DIFDELCMD < \\
%DIFDELCMD <         \hline 
%DIFDELCMD <     \end{tabular}
%DIFDELCMD < \label{tbl:ks_test_results}
%DIFDELCMD <  \vspace{-5pt}
%DIFDELCMD < \end{table}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{test shows the possibility of information that can be extracted to generate a physics-based reliability feature vector for the PIR sensor. This also motivates using classification techniques to identify the information difference between different failure scenarios~\mbox{%DIFAUXCMD
\cite{breiman2001random,cunningham2020k}}\hskip0pt%DIFAUXCMD
.
}\DIFaddend 

\begin{figure}
    \DIFdelbeginFL %DIFDELCMD < \begin{minipage}[t]{\columnwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.45\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\columnwidth]{figures/classification/BH/BH-feature-selection.png}
%DIFDELCMD < 			\vspace{-25pt}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/classification/BH/BH-feature-selection.png}
        \DIFaddendFL \caption{\DIFdelbeginFL %DIFDELCMD < \footnotesize{Top 10 features selected using B-H procedure.}%%%
\DIFdelendFL }
        \label{fig:BH_feature_selection}
    \DIFdelbeginFL %DIFDELCMD < \end{minipage}
%DIFDELCMD < 	\vspace{-20pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \end{subfigure}
    \hfill \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/classification/shapley/shap_expected_4.png}
        \caption{}
        \label{fig:shapley_summary}
    \end{subfigure}
    \caption{\ca \DIFaddFL{Top 10 features selected using B-H procedure, }\cb \DIFaddFL{Summary of Shapley Values showing FFT coefficients separate faulty and working classes.}}
\DIFaddendFL \end{figure}
\DIFaddbegin 


\DIFaddend \subsection{Feature Selection and Importance} 
\label{subsec:bh} 
We use \DIFaddbegin \DIFadd{both }\DIFaddend the time domain and frequency domain features of the \aout signal to classify the sensor to either working or one of the faulty classes. As the number of features that can be derived is huge (\eg in our case 305), we use the Benjamini-Hochberg (B-H) feature selection algorithm ~\cite{benjamini1995controlling} to estimate and analyze \textit{feature importance} in the \aout collected for working and each class of faulty sensors.

\DIFdelbegin \DIFdel{This }\DIFdelend \DIFaddbegin \DIFadd{B-H }\DIFaddend technique is used offline with training data to decide which features are useful in predicting the label of the sensor (\eg working vs. class X). The output of B-H feature selection process is a \DIFdelbegin \DIFdel{feature importance score (F-score) }\DIFdelend \DIFaddbegin \textit{\DIFadd{feature importance score (F-score)}} \DIFaddend that indicates how useful or valuable each feature is in the decision making process. The higher the F-score, the more important the feature is to \DIFdelbegin \DIFdel{the }\DIFdelend prediction. 

B-H feature selection process works by initially training an ensemble of decision trees on all features, derived from both time and frequency domain features as mentioned in Christ~\etal~\cite{christ2018time} and implemented in the open source library \texttt{tsfresh}~\cite{tsfresh2018code}. It then measures the prediction accuracy using every feature. This gives a high accuracy at the expense of overfitting. Thereafter, each feature vector is independently evaluated with respect to its significance for prediction using hypothesis testing, assigning it a F-score. It then iteratively prunes features having low F-scores, trains decision trees using these reduced features and measures prediction accuracy. The process stops when a user-set threshold of accuracy is met or when all the combinations have been tested. 

Applying the B-H process to our training data containing both faulty and working sensors, \emph{we pruned 305 features for our entire data set to obtain 10 features at a slightly better accuracy}. {\bfseries Fig.~\ref{fig:BH_feature_selection}} \DIFdelbegin \DIFdel{. }\DIFdelend plots the F-score for the selected 10 key features in both time and frequency domains. These include: \ca FFT Variance that indicates how spread the frequency distribution is, \cb Autocorrelation that generalizes periodicity or patterns in the time domain, and \cc  Measures of central tendency such as mean, median and change quantiles that measure the time domain changes within a corridor. This process is performed offline and the significance of the pruned feature set is guaranteed by the B-H algorithm. \DIFaddbegin \DIFadd{Both Friedrich coefficients and Peaks of support capture short term dynamics of the signal. The mathematical definition of these features can be found in statistics textbooks~\mbox{%DIFAUXCMD
\cite{tsfresh2018code}}\hskip0pt%DIFAUXCMD
. 
}\DIFaddend 








\subsection{Monitoring Feature Performance using Shapley Additive Explanations (SHAP)} \label{subsec:shap} Once the important features are identified using the B-H feature selection process, we use the technique of SHAP~\cite{NIPS2017_8a20a862} values to \textit{explain or interpret} the output of a prediction. SHAP uses game-theoretic techniques to explain how the output of a prediction changes by conditioning on every feature present in the reduced feature set given by B-H process.  






\DIFdelbegin %DIFDELCMD < \begin{figure}\begin{minipage}{\linewidth}
%DIFDELCMD < 	\scalebox{0.95}{
%DIFDELCMD < 		\centering
%DIFDELCMD < \includegraphics[width=\linewidth]{figures/classification/shapley/shap_expected_4.png}
%DIFDELCMD < 		}
%DIFDELCMD < 		%%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{Summary of Shapley Values} %%%
\DIFdelFL{showing FFT coefficients separate faulty and working classes.}}
		%DIFAUXCMD
%DIFDELCMD < \label{fig:shapley_summary}
%DIFDELCMD < 		\vspace{-15pt}
%DIFDELCMD < 	\end{minipage}
%DIFDELCMD < \end{figure}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend {\bfseries Fig.~\ref{fig:shapley_summary}} shows an example of how SHAP values are analyzed for a particular prediction on a classification between faulty and working sensors. The features in red contribute to the sensor being predicted as faulty, whereas the features in blue contribute to the sensor being predicted as working. \DIFaddbegin \DIFadd{As seen, the competing features that contributed to this decision are the FFT coefficients and the statistical features~}\viz \DIFadd{mean, median and covariance. 
}\DIFaddend In this prediction, the FFT coefficients push the prediction to that of a faulty sensor while the mean, median and covariance push the prediction to a working sensor. The base value is the average SHAP value output by the model for the entire training dataset, and the value in bold is the SHAP value for this particular prediction. We leverage an open-source library implementation of the algorithm from Lundberg~\etal~\cite{NIPS2017_8a20a862, shap_implementation} that sorts the features by \DIFdelbegin \DIFdel{the }\DIFdelend sum of SHAP value magnitudes over all the samples and conditionally rejects the feature contributing \DIFdelbegin \DIFdel{the }\DIFdelend lowest to the prediction. Thus, we use the feature explanations from SHAP values to tune the model performance. 

\subsection{\sol: Fault Detection \& Analysis Algorithm}
\label{subsec:high_level_algorithm}
We now \DIFdelbegin \DIFdel{present our algorithm}\DIFdelend \DIFaddbegin \DIFadd{combine the insights gathered from physics and machine learning techniques to develop a unified algorithm, called }\DIFaddend \sol\DIFdelbegin \DIFdel{towards fault detection in PIR sensors}\DIFdelend \DIFaddbegin \DIFadd{, that is deployable at the edge, to isolate and diagnose faults}\DIFaddend .
\sol consists of 2 stages: \ci pre-deployment (training) stage, wherein the reference \aout values for a set of sensors (both working and faulty) are collected \DIFdelbegin \DIFdel{in an offline manner and analysed }\DIFdelend \DIFaddbegin \DIFadd{offline and analyzed }\DIFaddend to extract key features and \cii deployment stage, wherein the features from a operational \aout signal is matched with \DIFaddbegin \DIFadd{the }\DIFaddend previously extracted features in order to detect and isolate faults. We next describe both the stages in detail.


\begin{figure}
	\DIFdelbeginFL %DIFDELCMD < \centering
%DIFDELCMD < 	%%%
\DIFdelendFL \begin{minipage}[t]{0.26\textwidth}
		\centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=0.85\textwidth]{figures/deployment/predeployment-stage-2.png}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=0.9\textwidth]{figures/deployment/predeployment-stage-2.png}
\DIFaddendFL \caption{\DIFdelbeginFL %DIFDELCMD < \footnotesize{ Pre-deployment stage}%%%
\DIFdelendFL \DIFaddbeginFL \footnotesize{Pre-deployment stage}\DIFaddendFL .}
\label{fig:pre_deployment_steps}
	\end{minipage}\DIFdelbeginFL \DIFdelFL{\hspace{1ex}
	}%DIFDELCMD < \begin{minipage}[t]{0.2\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \hfill
    \begin{minipage}[t]{0.22\textwidth}
		\DIFaddendFL \centering
		\includegraphics[width=0.7\textwidth]{figures/deployment/deployment-stage-5.png}
\caption{\footnotesize{Deployment stage}.}
\label{fig:deployment_steps}
	\end{minipage}
    \DIFdelbeginFL %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \hfill
    \begin{minipage}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/classification/accuracy_vs_window_size.png}
		\caption{\footnotesize{Model Accuracy} \DIFaddFL{for different window sizes. We choose 1024 as the default window size.}}
		\label{fig:accuracy_vs_window_size}
    \end{minipage}
\DIFaddendFL \end{figure}







\subsubsection{Pre-deployment stage} 
\label{sebsec:pre_deploy} 
We first collect \aout from a set of sensors, \DIFaddbegin \DIFadd{comprising }\DIFaddend both working and faulty \DIFaddbegin \DIFadd{ones such as the ones shown in }{\bfseries \DIFadd{Fig.~\ref{fig:pir_sensor_failure_photographs}}}\DIFaddend . The collected time series data are labeled to form a training dataset. We perform the Benjamini-Hochberg \DIFaddbegin \DIFadd{(B-H) }\DIFaddend feature selection on this dataset to extract key features such as FFT coefficients of \aout for each class of sensor. This forms a feature dictionary containing a smaller number of features along with the failure as a label. We further verify the importance of these features using SHAP analysis and refine \DIFdelbegin \DIFdel{if required}\DIFdelend \DIFaddbegin \DIFadd{the features if necessary}\DIFaddend .
We then build a classifier model to uniquely identify the \DIFdelbegin \DIFdel{failure in the sensor }\DIFdelend \DIFaddbegin \DIFadd{sensor failure }\DIFaddend and load this model into the edge device connected to the PIR sensor. 

We now describe the steps involved ({\bfseries Fig.~\ref{fig:pre_deployment_steps}}):
\circled{1} We deploy the working and faulty sensors for a short duration (say few days) in a real-world environment to collect realistic \aout signals for low, medium and high occupancy. 
Note \DIFaddbegin \DIFadd{that }\DIFaddend this is a one-time activity performed for a specific PIR sensor type/manufacturer. 
We used 15 sensors comprising a mix of working and faulty sensors capturing failures in each class as our training set.
\circled{2} We note the label of a sensor and split the \aout values into equal-sized time \DIFdelbegin \DIFdel{windows }\DIFdelend \DIFaddbegin \DIFadd{slices (windows) }\DIFaddend to calculate different time and frequency-domain features. 
\circled{3} We apply B-H feature selection process for each type of sensor to identify unique and key features. 
\circled{4} We performed SHAP analysis to understand the performance of each feature towards classification and refine them accordingly. 
\circled{5} We use the final set of features along with class labels to build a classifier model \DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{(we }\DIFaddend use random forest as our classifier model\DIFaddbegin \DIFadd{)}\DIFaddend . This model is then loaded onto the edge devices for fault detection and analysis. \DIFaddbegin \DIFadd{We note that while }\circled{2} \DIFadd{and }\circled{3} \DIFadd{are computationally expensive, it is acceptable as it is performed offline only once in the pre-deployment.
}\DIFaddend 


\subsubsection{Deployment stage} 
This stage consists of the following steps ({\bfseries Fig.~\ref{fig:deployment_steps}}): 
\circled{6} First, the operational \aout output signals for the deployed sensors are collected. 
\circled{7} We split the \aout into equal-sized windows using \DIFaddbegin \DIFadd{same window size as in }\DIFaddend the pre-deployment\DIFdelbegin \DIFdel{window sizes}\DIFdelend . 
\circled{8} We extract the necessary features from the \aout signal. 
\circled{9} We use a classifier to \ca isolate faulty from working sensors and \cb identify the class of failure in the faulty sensor if applicable. \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{As mentioned earlier, the pre-deployment stage (to collect features and build a classifier model) is a one-time activity. }\DIFdelend The fault detection (steps \circled{6} - \circled{9}) depends on the application requirements, \ie every hour, day or week. 











 \DIFdelbegin %DIFDELCMD < \begin{figure}
%DIFDELCMD < \centering
%DIFDELCMD < 		\includegraphics[width=0.85\columnwidth, height=1.05in]{figures/classification/accuracy_vs_window_size.png}
%DIFDELCMD < 		\vspace{-15pt}
%DIFDELCMD < 		%%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{Model Accuracy} %%%
\DIFdelFL{for different window sizes. We choose 1024 as the default window size.}}
		%DIFAUXCMD
%DIFDELCMD < \label{fig:accuracy_vs_window_size}
%DIFDELCMD < 		\vspace{-15pt}
%DIFDELCMD < \end{figure}
%DIFDELCMD < 

%DIFDELCMD < \begin{figure}
%DIFDELCMD <     \centering
%DIFDELCMD <     \includegraphics[width=\columnwidth,height=0.8in]{figures/platform/sensys_workflow-redraw-camera.png}
%DIFDELCMD <     		\vspace{-15pt}
%DIFDELCMD <     %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
%DIFDELCMD < \footnotesize{Workflow} %%%
\DIFdelFL{of }%DIFDELCMD < \sol %%%
\DIFdelFL{for fault detection and diagnosis.}}
    %DIFAUXCMD
%DIFDELCMD < \label{fig:system_workflow}
%DIFDELCMD <     \vspace{-20pt}
%DIFDELCMD < \end{figure} \vspace{-5pt}
%DIFDELCMD < %%%
\DIFdelend \section{Implementation}
\label{sec:impl}

Our solution is designed using commodity off the shelf (COTS) components.
\DIFdelbegin \DIFdel{Our open sourced }\DIFdelend \DIFaddbegin \DIFadd{The open-source }\DIFaddend implementation\footnote{Available at: \url{https://github.com/synercys/PIRMedic}} includes:



\ca \textbf{Edge Hardware} consisting of -- \ci a PIR sensor~\cite{PIR_sensor_eval}, \cii a bare-metal platform~\viz Arduino Mega Microcontroller Unit (MCU)\DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{arduino_mega} 
}\hskip0pt%DIFAUXCMD
}\DIFaddend for sensor data capture, and \ciii a linux-based platform~\viz Raspberry Pi\DIFdelbegin \DIFdel{for performing }\DIFdelend \DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{rpi3} 
}\hskip0pt%DIFAUXCMD
for executing }\DIFaddend the fault detection and diagnosis \DIFaddbegin \DIFadd{algorithm, }\sol\DIFaddend .



The Arduino MCU polls the sensor hardware signals (\ie \cout and \aout) periodically over a GPIO interface. We poll the PIR sensors at a frequency $\geq$ 20 Hz due to the \textit{Nyquist criterion} as the human motion information in the PIR sensor is between 0 -- 10 Hz. \DIFaddbegin \DIFadd{Note that using a bare-metal platform allows us to capture }\aout \DIFadd{samples at a constant rate. }\DIFaddend The Raspberry Pi platform performs the \DIFaddbegin \DIFadd{fault }\DIFaddend detection and analysis \DIFdelbegin \DIFdel{of faults }\DIFdelend for the data captured at the Arduino MCU.
\DIFaddbegin \DIFadd{The Raspberry Pi and Arduino are connected via a Micro-USB cable and the data captured at the Arduino MCU is serially transferred to the Raspberry Pi for analysis. 
}\DIFaddend 

\cb \textbf{Edge Implementation} We used standard python libraries such as \texttt{tsfresh}~\cite{tsfresh2018code,christ2016distributed} for \DIFdelbegin \DIFdel{FFT implementations to implement }\DIFdelend \DIFaddbegin \DIFadd{computing features such as FFT and other statistical features as a part pf }\DIFaddend feature extraction, \texttt{numpy} for data preprocessing and 
\texttt{xgboost}~\cite{shap_implementation} for implementing the machine learning classifiers. The end-to-end workflow of our solution is illustrated in {\bfseries Fig.~\ref{fig:system_workflow}}.

\DIFdelbegin %DIFDELCMD < \vspace{-5pt}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth,height=0.8in]{figures/platform/sensys_workflow-redraw-camera.png}
	\caption{\footnotesize{Workflow} \DIFaddFL{of }\sol \DIFaddFL{for fault detection and diagnosis.}}
	\label{fig:system_workflow}
\end{figure}








\DIFaddend \subsection{Parameters of \sol}
\label{subsec:prac} 
\ci \textbf{Size of Window}: The collected \aout waveform is split into equal-size sample windows over which features are calculated. We observed that using a window too small (\eg 128) does not allow us to capture sufficient features for a failure type and \DIFdelbegin \DIFdel{can }\DIFdelend \DIFaddbegin \DIFadd{could }\DIFaddend lead to a large number of false alarms. Also, \DIFdelbegin \DIFdel{a large }\DIFdelend \DIFaddbegin \DIFadd{too large of a }\DIFaddend window size (\eg 8192) leads to an overlap in the features of multiple failure classes leading to a loss of accuracy. The variation of model accuracy as a function of window size is shown in {\bfseries Fig.~\ref{fig:accuracy_vs_window_size}}. We chose a window size of 1024 samples 
as it gave us a good \DIFdelbegin \DIFdel{tradeoff }\DIFdelend \DIFaddbegin \DIFadd{trade-off }\DIFaddend between time to capture a window (\DIFaddbegin \DIFadd{approx. }\DIFaddend 50 seconds) and accuracy (> 98\%).

\cii \textbf{Benjamini-Hochberg (B-H) Feature Selection} While there are more than 300 features that can be derived for time series analysis of \aout, B-H feature selection process (derived from parameterized hypothesis testing)~\cite{benjamini1995controlling,christ2018time} prunes this to a lower number of features that can sufficiently capture the physics of the system. We observed that using more than 10 features did not contribute to a significant increase in accuracy (beyond 98\%) and can, in practice, lead to lower performance due to overfitting as described in \S\ref{subsec:bh}.

\ciii \textbf{Classifier Model}: We used a Random Forest classifier~\DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{polikar2012ensemble} }\hskip0pt%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{polikar2012ensemble, breiman2001random} }\hskip0pt%DIFAUXCMD
}\DIFaddend owing to the capability to classify data based on ``entropy'' or the information gain.  Random Forest uses an ensemble of trees and has been shown to give high predictive accuracy and control over-fitting in practice, both of which are issues with decision trees\DIFdelbegin \DIFdel{~\mbox{%DIFAUXCMD
\cite{polikar2012ensemble}}\hskip0pt%DIFAUXCMD
}\DIFdelend . Additionally, Random Forests are amenable to interpretation by techniques such as Shapley TreeExplainer\DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{lundberg2020local2global} }\hskip0pt%DIFAUXCMD
}\DIFaddend that explains the features influencing \DIFdelbegin \DIFdel{the }\DIFdelend prediction. \textit{Finally, we note that \aout is compatible with any classification algorithm.}








%



\section{Evaluation}
\label{sec:evaluation}
The evaluation is intended to answer the following questions -- \ca can we detect failures~\ie separate faulty \DIFaddbegin \DIFadd{PIR }\DIFaddend sensors from working \DIFdelbegin \DIFdel{sensors}\DIFdelend \DIFaddbegin \DIFadd{ones}\DIFaddend ? and \cb what can we learn about the failure? In other words, can we perform diagnosis that can aid in replacing or repairing the sensor? We answer these questions in practical deployments, each consisting of the following stages:

\ca {\bfseries Stage I: Failure Detection} The goal of this stage is to isolate defective, faulty sensors from functional, working sensors. \DIFaddbegin \DIFadd{Note that we do not diagnose the failure in this stage }\ie \DIFadd{the sensors deemed faulty could be so due to multiple, as yet unknown reasons.}\DIFaddend \\
\hspace*{2ex}\cb {\bfseries Stage II: Failure Diagnosis} In this stage, we diagnose the failure by mapping it to the taxonomy defined in \S\ref{subsec:taxonomy}. \DIFdelbegin \DIFdel{In other words}\DIFdelend \DIFaddbegin \DIFadd{Using the taxonomy as a reference}\DIFaddend , we seek to conclude whether it is the lens, pyroelectric or electronics subsystem that contains the failure.\\
\hspace*{2ex}\cc {\bfseries Stage III: Fine-Grained Fault Analysis} In this stage, we learn details about the failure as precisely as possible. \Eg if we \DIFdelbegin \DIFdel{identify }\DIFdelend \DIFaddbegin \DIFadd{attribute }\DIFaddend a fault to be \DIFdelbegin \DIFdel{due to }\DIFdelend Class III failure, we seek to narrow it down to see if it is due to deposition of dust or paper on the lens.







\subsection{Real-world Deployments}
\label{subsec:deployment}



We performed the following \emph{deployments across multiple scenarios} -- 
\ca in the elevator of a building (\S\ref{subsubsec:elevator}), 
\cb in the lobby of a building (\S\ref{subsubsec:lobby}), \cc in a \DIFdelbegin \DIFdel{starbucks }\DIFdelend \DIFaddbegin \DIFadd{Starbucks }\DIFaddend coffee shop (\S\ref{subsubsec:starbucks})\DIFaddbegin \DIFadd{, and }\cd \DIFadd{in a cafeteria (\S\ref{subsubsec:cafeteria}) (India)}\DIFaddend .
The different deployment scenarios \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \ca \DIFadd{-- }\cc \DIFadd{are }\DIFaddend shown in {\bfseries Fig.~\ref{fig:pir_deployment_scenario}}, \DIFaddbegin \DIFadd{and aim to }\DIFaddend capture diverse environmental conditions and challenges (heat, dust, humidity~\etc). 
We used 15 sensors in total across all our deployments comprising of 5 working sensors and 2 \DIFdelbegin \DIFdel{sensors belonging to each faulty }\DIFdelend \DIFaddbegin \DIFadd{faulty sensors per }\DIFaddend class. A combination of these was used in each of our deployments.
These sensors were deployed (\textbf{Fig.~\ref{fig:pir_sensor_failure_photographs}}) over a duration of 3 months and collected data both during times of low occupancy (weekends, late nights) and high occupancy (weekdays, working hours). Note that no \DIFaddbegin \DIFadd{auxiliary }\DIFaddend private data such as audio or video were captured during \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{these }\DIFaddend deployments.

\begin{figure}[t!]
\centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=0.15\textwidth, height=1in]{figures/deployment/coffee_shop/Starbucks-jpg.jpg}
%DIFDELCMD < 	\includegraphics[width=0.15\textwidth, height=1in]{figures/deployment/elevator/Elevator-jpg.jpg}
%DIFDELCMD < 	\includegraphics[width=0.15\textwidth, height=1in]{figures/deployment/lobby/lobby.jpg}
%DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=0.3\textwidth, height=1.33in]{figures/deployment/elevator/Elevator-jpg.jpg}
	\includegraphics[width=0.3\textwidth]{figures/deployment/lobby/lobby.jpg}
	\includegraphics[width=0.3\textwidth]{figures/deployment/coffee_shop/Starbucks-jpg.jpg}
\DIFaddendFL \caption{\footnotesize{Deployment Scenarios} used for evaluating \DIFdelbeginFL \DIFdelFL{our }\DIFdelendFL \DIFaddbeginFL \sol \DIFaddFL{in PIR sensor }\DIFaddendFL failure \DIFdelbeginFL \DIFdelFL{analysis}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{detection and diagnosis~}\viz \DIFaddFL{Elevator, Lobby of a building and Starbucks coffee shop}\DIFaddendFL .}
\label{fig:pir_deployment_scenario}
\DIFdelbeginFL %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure}
\begin{figure*}
    \DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.37\textwidth}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.4\textwidth}
\DIFaddendFL \includegraphics[width=\textwidth]{figures/deployment/elevator/afternoon-6hr.png}
\DIFdelbeginFL %DIFDELCMD < \vspace{-20pt}
%DIFDELCMD <     	%%%
\DIFdelendFL \caption{}
    	\label{fig:deployment_csl_elevator}\end{subfigure}\hfill \begin{subfigure}[b]{0.59\textwidth}
	    \DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\textwidth, height=0.75in]{figures/deployment/elevator/confusion-matrix-elevator-camera-ready.png}
%DIFDELCMD < 	    \vspace{-12pt}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth, height=0.65in]{figures/deployment/elevator/confusion-matrix-elevator-camera-ready.png}
		\DIFaddendFL \caption{}
		\label{fig:elevator_classification_results}
	\end{subfigure}\DIFdelbeginFL %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < %%%
\DIFdelendFL \caption{\footnotesize Elevator Deployment \ca Occupancy : The graph is a 6 hour deployment during business hours, \cb Deployment Statistics and confusion matrix of the classification model. Column titles: \textbf{WIN}$\rightarrow$Total Number of Windows, \textbf{MO}$\rightarrow$Misses Obstacle, \textbf{FD}$\rightarrow$ False Detection.}
\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure*}
\begin{figure*}
	\centering
	\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.37\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.4\textwidth}
		\DIFaddendFL \centering
		\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\textwidth, height=0.8in]{figures/deployment/lobby/lateafternoon-3hrs.png}
%DIFDELCMD < 			\vspace{-20pt}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/deployment/lobby/lateafternoon-3hrs.png}
		\DIFaddendFL \caption{}
        \label{fig:deployment_csl_lobby}\end{subfigure}\hfill \DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[b]{0.58\textwidth}
%DIFDELCMD < 	    %%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[b]{0.59\textwidth}
	    \DIFaddendFL \centering
	    \DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\columnwidth]{figures/deployment/lobby/confusion-matrix-lobby-camera-ready.png}
%DIFDELCMD < 	    \vspace{-13pt}
%DIFDELCMD < 	    %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\textwidth]{figures/deployment/lobby/confusion-matrix-lobby-camera-ready.png}
\DIFaddendFL \caption{}
	    \label{fig:lobby_classification_results}
	\end{subfigure}
\DIFdelbeginFL %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \caption{\footnotesize Lobby Deployment \ca Occupancy graph during late evening from 6.45 pm to 9.45 pm at the lobby of our university building, \cb Deployment Statistics and confusion matrix of the classification model. Column titles: \textbf{WIN}$\rightarrow$Total Number of Windows, \textbf{MO}$\rightarrow$Misses Obstacle, \textbf{FD}$\rightarrow$ False Detection.} 
\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure*}
\begin{figure*}
	\DIFdelbeginFL %DIFDELCMD < \begin{subfigure}[t]{0.39\textwidth}
%DIFDELCMD < 		%%%
\DIFdelendFL \DIFaddbeginFL \begin{subfigure}[t]{0.4\textwidth}
		\DIFaddendFL \centering
		\includegraphics[width=\textwidth]{figures/deployment/coffee_shop/starbucks_4hr_deployment.png}
\DIFdelbeginFL %DIFDELCMD < \vspace{-20pt}
%DIFDELCMD < 		%%%
\DIFdelendFL \caption{}
		\label{fig:deployment_starbucks}
	\end{subfigure}\hfill \begin{subfigure}[b]{0.59\textwidth}
	    \centering
	    \includegraphics[width=\columnwidth]{figures/deployment/coffee_shop/confusion-matrix-coffeeshop-camera-ready.png}
	    \caption{}
	    \label{fig:coffeeshop_classification_results}
	\end{subfigure}
\DIFdelbeginFL %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \caption{\footnotesize \textbf{Starbucks Deployment Occupancy}: Evening deployment from 4.45 pm to 8.45 pm. The second half has much lesser little foot traffic. \cb Deployment Statistics and confusion matrix of the classification model. Column titles: \textbf{WIN}$\rightarrow$Total Number of Windows, \textbf{MO}$\rightarrow$Misses Obstacle, \textbf{FD}$\rightarrow$ False Detection. }
\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure*}


















\subsubsection{Deployment in a University Elevator (US)}\label{subsubsec:elevator} 
We deployed working and faulty sensors along the inside wall of an elevator in our university research building (middle {\bfseries Fig.~\ref{fig:pir_deployment_scenario}}). 
The data collection captured scenarios of both high and low occupancy during and outside of business hours. In addition to faulty sensors, we placed a \DIFaddbegin \DIFadd{normal, }\DIFaddend working sensor to keep track of the actual motion in the elevator. 
{\bfseries Fig.~\ref{fig:deployment_csl_elevator}} plots \cout and \aout values captured by \DIFdelbegin \DIFdel{normal sensors }\DIFdelend \DIFaddbegin \DIFadd{the working sensor }\DIFaddend showing the actual traffic in the elevator on one of the days.\DIFdelbegin \DIFdel{The vertical }\DIFdelend \DIFaddbegin \DIFadd{Vertical }\DIFaddend stripes on the graph showing \DIFdelbegin \DIFdel{the }\DIFdelend oscillations of \cout (in blue) are points of occupancy \ie \DIFdelbegin \DIFdel{person entered}\DIFdelend \DIFaddbegin \DIFadd{denoting a person's entry}\DIFaddend /\DIFdelbegin \DIFdel{exited }\DIFdelend \DIFaddbegin \DIFadd{exit at }\DIFaddend the elevator. Likewise, \DIFdelbegin \DIFdel{the }\DIFdelend regions of graph \DIFdelbegin \DIFdel{where there is }\DIFdelend \DIFaddbegin \DIFadd{with }\DIFaddend no occupancy is represented by a flat line, hovering around 3.7 V. 

\newcommand{\elevatortable}{\footnotesize
		\centering
		\begin{tabular}{ | l | c | c | }
			\hline
			\multirow{2}{*}{\bfseries \textsc{Fault Present}} & 
			\multicolumn{2}{c|}{\bfseries WIN = 2432} \\
			\cline{2-3}
			& \bfseries MO &  \bfseries FD \\ \hline \hline
			Lens Dislodged &  343 & 50   \\ \hline
			Lens Covered with Black Tape &  529 & 0   \\ \hline
			Pyroelectric Element Heat Damage &  247 &  55 \\ \hline
			Optical Filter Covered & 526 & 0  \\ \hline
			Sensor Board Short & 529 & 0 \\ \hline
		\end{tabular}			
}





For faulty sensors, we measure the number of time windows where an obstacle was captured or missed. 
The performance of faulty sensors relative to a working sensor is tabulated in {\bfseries Fig.~\ref{fig:deployment_csl_elevator}}. 
When the lens cap is dislodged, it misses obstacles in 343 time windows whereas the (thermal) breakage of the pyroelectric element results in 247 misses. 
Overall, we observe that missed obstacles are more common than false alarms.
This ties into common observations in conference rooms operated with PIR sensor-controlled lighting, where lights turn off even with occupants present.


As described in \S\ref{subsec:high_level_algorithm}, \sol collects the \aout signals and uses a machine learning model on their extracted features detect faulty sensors. Using a random forest classifier, we \DIFdelbegin \DIFdel{observe that }\DIFdelend \DIFaddbegin \DIFadd{obtain }\DIFaddend the confusion matrix ({\bfseries Fig.~\ref{fig:elevator_classification_results}})\DIFaddbegin \DIFadd{, which }\DIFaddend shows that predicted label matches the true label for each failure. 
We note that -- \ca the working sensor has distinct characteristics compared to the faulty sensors and is isolated correctly, \cb \DIFdelbegin \DIFdel{the }\DIFdelend faulty sensors with different failures in lens and pyroelectric subsystem are identified to the failure class correctly as observed by diagonal of the confusion matrix. \DIFdelbegin \DIFdel{Clearly, }\DIFdelend \DIFaddbegin \DIFadd{This implies that }\DIFaddend the features of \aout, derived by \sol is able to differentiate between lens being dislodged, lens being covered with tape, oil condensation on the optical filter and \DIFdelbegin \DIFdel{the }\DIFdelend heat damage on the pyroelectric element.






\subsubsection{Deployment in a University Lobby (US)}\label{subsubsec:lobby} We deployed our sensors in the first floor lobby space of our university building. 
The lobby deployment is noisier with fewer constraints on direction of motion, compared to the confined space of an elevator.
\DIFaddbegin \DIFadd{As in the elevator deployment, we deployed a combination of working and faulty sensors shown in the table in }{\bfseries \DIFadd{Fig.~\ref{fig:lobby_classification_results}}}\DIFadd{. 
}\DIFaddend 




\textbf{Fig.~\ref{fig:deployment_csl_lobby}} shows a 3 hour slice of the deployment. The vertical stripes on \cout correspond to traffic entering/exiting the lobby in the field of view. 
The performance of the sensors deployed, in terms of false detection and missed obstacles, is shown in the table in {\bfseries Fig.~\ref{fig:lobby_classification_results}}. The sensors with lens dislodged missed a large amount of obstacles. This is due to the lack of focus of thermal radiation on the pyroelectric element resulting in dispersion of radiation due to the large lobby area. As a result of this failure, only obstacles that line up in the reduced field of view, are captured. \DIFdelbegin \DIFdel{(}\DIFdelend This issue is not present in an elevator due to its confined space.
\DIFdelbegin \DIFdel{) 
}\DIFdelend \DIFaddbegin \DIFadd{Other faults such as lens deformation and damage due to oil condensation experienced lesser number of misclassifications. 
}\DIFaddend Upon extracting the features of the \aout signals, and classifying it using the procedure in \S\ref{subsec:high_level_algorithm}, we observe the confusion matrix as shown in {\bfseries Fig.~\ref{fig:lobby_classification_results}}. The high fraction along the diagonal shows that a majority of sensor failures are classified and identified correctly\DIFaddbegin \DIFadd{, as the features are able to bring out differences in the physics of failures}\DIFaddend .
Note that we observe some misclassifications of sensor faults (\eg for C). We argue that this is due to the deployment area of a lobby being open and the limited coverage area of the sensor, both of which can lead to imperfect \DIFdelbegin \DIFdel{data }\DIFdelend \DIFaddbegin \DIFadd{capture }\DIFaddend at the periphery. Consequently, for traffic at the edges \DIFdelbegin \DIFdel{, the }\DIFdelend \DIFaddbegin \DIFadd{of field of view, this }\DIFaddend reduced thermal radiations \DIFdelbegin \DIFdel{can }\DIFdelend \DIFaddbegin \DIFadd{could }\DIFaddend lead to some misclassifications. 







\subsubsection{Deployment in a Starbucks (US)}\label{subsubsec:starbucks} 
We deployed \DIFdelbegin \DIFdel{our }\DIFdelend PIR sensors near the ordering queue of the coffee shop during business hours to capture the typical foot traffic (left {\bfseries Fig.~\ref{fig:pir_deployment_scenario}}). 
Our deployment captured linear, regularized bidirectional movement (entry followed by exit of the region of interest) ({\bfseries Fig.~\ref{fig:deployment_starbucks}}).
Our deployment lasted for a duration of 4 hours on a busy Friday evening. 
We observed that out of 226 time windows (each containing 1024 samples), there were missed obstacles across: \ci 27 windows in class I, \cii 35 windows in class II, \ciii 26 windows in class III and no windows in class IV. 
The missed obstacles and false \DIFdelbegin \DIFdel{detections }\DIFdelend \DIFaddbegin \DIFadd{detection }\DIFaddend (none in this case) are summarized in {\bfseries Fig.~\ref{fig:coffeeshop_classification_results}}. 
Using \sol, we observe high fractions along the diagonal of the confusion matrix; hence the predicted label of sensor failure matches the true label.


\DIFdelbegin %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{Furthermore, despite the oil impurity not being enough cause it to alter performance, we still classify it is a separate class from the physics point of view due to its different behavior of }\aout \DIFadd{from that of a working sensor.
Thus, in line with the previous deployments, we can use the features of }\aout \DIFadd{to form a signature of the physics. 
}










\subsubsection{\DIFadd{Deployment in a Cafeteria}}\label{subsubsec:cafeteria} \DIFadd{To evaluate the analysis of }\aout \DIFadd{during quiet times, we deployed a mix of 3 types of sensors with lens failures -- lens fallen off, lens covered and some working sensors during the lunch hour at a cafeteria in India. The traffic during lunchtime in the cafeteria is as shown in }{\bfseries \DIFadd{Fig.~\ref{fig:deployment_msr_cafeteria}}}\DIFadd{. As these were lens-related failures, we looked at the time-domain characterization of }\aout \DIFadd{during quiet times to understand the status of lens. The time domain representation of }\aout\DIFadd{, during a period of no occupancy, is as shown in }{\bfseries \DIFadd{Fig.~\ref{fig:variance_cap_cases}}}\DIFadd{. The y-axis is plotted in terms of the 10-bit ADC representations of voltage to highlight the differences. For a 10-bit ADC, 1023 units (}\ie \DIFadd{$2^{10} - 1$) corresponds to a voltage of 5 V. Therefore, a voltage of 1.8 V corresponds to 340 units. 
}

\DIFadd{We note visually that the noise floor at output of the lens subsystem is higher with the lens dislodged (}{\bfseries \DIFadd{Fig.~\ref{fig:capoff}}}\DIFadd{) as compared to both a normal sensor (}{\bfseries \DIFadd{Fig.~\ref{fig:capon}}}\DIFadd{) and one with lens covered (}{\bfseries \DIFadd{Fig.~\ref{fig:capcovered}}}\DIFadd{). Specifically, we observed a variance of 10 $Volt^2$ when lens was covered, 250 $Volt^2$ when lens was in place and working, and 1500 $Volt^2$ when lens had fallen of completely. Consequently, a low threshold ($T_L$) of 100 $Volt^2$ and a high threshold ($T_H$) of 1000 $Volt^2$ was sufficient to separate between the 3 types of sensors. Note that the variance had to be computed during a quiet period of no traffic in this case. 
}




\begin{figure*}
	\begin{minipage}[t]{0.48\textwidth}
\includegraphics[width=6cm]{figures/deployment/bangalore-cafetria/msr-cafeteria-15mins.png}
		\vspace{-5pt}
		\caption{\textbf{\DIFaddFL{Cafeteria Deployment occupancy}} \DIFaddFL{during lunchtime. A 15 min. slice of traffic at the checking counter.}}
		\label{fig:deployment_msr_cafeteria}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
\vspace{-\baselineskip}
\begin{tabular}{l c c c c c}
					\hline
					\textbf{\DIFaddFL{Training (MB)}} & \textbf{\DIFaddFL{32}} & \textbf{\DIFaddFL{64}} & \textbf{\DIFaddFL{96}} & \textbf{\DIFaddFL{112}} & \textbf{\DIFaddFL{128}} \\
					\hline \hline
					\DIFaddFL{Accuracy (\%) }& \DIFaddFL{92.4 }& \DIFaddFL{95.8 }& \DIFaddFL{98.6 }& \DIFaddFL{99.1 }& \DIFaddFL{99.4 }\\
					\hline
				\end{tabular}
\vspace{\baselineskip}
			\caption{\textbf{\DIFaddFL{Failure detection accuracy}} \DIFaddFL{as a function of the size of training dataset}}
			\label{fig:dataset_size}
\end{minipage}
\end{figure*}


\begin{figure}\centering
	\begin{subfigure}[t]{0.33\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/pir/lens_fault/BuildSys_Graphs/CapCovered_NoObstacle.png}
		\caption{\DIFaddFL{Lens Covered Completely}}
		\label{fig:capcovered}
	\end{subfigure}
	\begin{subfigure}[t]{0.33\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/pir/lens_fault/BuildSys_Graphs/CapON_NoObstacle.png}
		\caption{\DIFaddFL{Lens in Place (Working)}}
		\label{fig:capon}
	\end{subfigure}
	\begin{subfigure}[t]{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/pir/lens_fault/BuildSys_Graphs/CapOff_NoObstacle.png}
		\caption{\DIFaddFL{Lens Dislodged}}
		\label{fig:capoff}
	\end{subfigure}
	\caption{\DIFaddFL{The variance in }\aout \DIFaddFL{during known quiet times contains hints about lens failures in the PIR sensor.}}
	\label{fig:variance_cap_cases}
\end{figure}






\DIFadd{We now discuss the different stages of }\sol\DIFadd{, as enumerated in the beginning of this section. 
}

\DIFaddend \subsection{Stage I -- Failure Detection}
\DIFaddbegin \label{subsec:fail_detection}
\DIFaddend 



We aggregated all the sensors (both working and faulty) to \textit{separate faulty sensors (without specifying which class) from working sensors}. 
We collected FFT coefficients of \aout on a pre-deployment lasting 1 week and performed daily collection of \aout signals from all the deployed sensors. 
We used a Random Forest classifier with specifications shown in {\bfseries Fig~\ref{fault_detection_results}}. 
Once predicted, we manually verified the true status of the sensor and observed an accuracy of over 99\% in predicting if the sensor is working or faulty. 
Thus, FFT-based features of \aout were able to capture the physics, and hence separate faulty sensor physics from working sensor physics.
\DIFaddbegin \DIFadd{We also varied the }\textit{\DIFadd{size of training dataset}} \DIFadd{(128 MB corresponds to 1 week pre-deployment) to show the robustness of failure detection in }{\bfseries \DIFadd{Fig.~\ref{fig:dataset_size}}}\DIFadd{.
}\DIFaddend 


\begin{comment}
	\begin{tcolorbox}[left=1pt,right=1pt,top=1ex,bottom=1pt,boxsep=0pt,
		toptitle=0.5ex,bottomtitle=0.5ex]
	{\bfseries Summary:} \ins{The FFT representation of \aout is used to perform binary classification between working and faulty sensors.}
	\end{tcolorbox}
\end{comment} 

\DIFdelbegin %DIFDELCMD < \begin{figure}[b]
%DIFDELCMD < 	\vspace{-\baselineskip}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \begin{wrapfigure}{R}{0.5\textwidth}
	\DIFaddendFL \centering
	\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=\columnwidth]{figures/classification/FaultDetectionResults.png}
%DIFDELCMD < 	\vspace{-2\baselineskip}
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=0.5\textwidth]{figures/classification/FaultDetectionResults.png}
	\DIFaddendFL \caption{\footnotesize Fault Detection showing that faulty sensors isolated from working sensors by extracting FFT of \aout and using a Random Forest Classifier.}
	\label{fault_detection_results}
\DIFdelbeginFL %DIFDELCMD < \vspace{-\baselineskip}
%DIFDELCMD < \end{figure}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \end{wrapfigure}
\DIFaddend 



%














































\DIFdelbegin %DIFDELCMD < \begin{figure*}[t]
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \begin{figure*}\DIFaddendFL \begin{subfigure}[t]{0.41\textwidth}
\includegraphics[width=\linewidth]{figures/2-PIR-Fault/all-5-combined/CDF_FFT.png}
		\caption{}
		\label{fig:cdf_combined_all}
	\end{subfigure}\hfill \begin{subfigure}[b]{0.16\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/classification/LensDefects/confusion-matrix-lensdefects.png}
		\caption{}
		\label{fig:finegrained_classification_results}
	\end{subfigure}\begin{subfigure}[t]{0.41\textwidth}
		\centering
\includegraphics[width=\linewidth]{figures/classification/LensDefects/Log_Aout_Paper_Plastic_Dust_Normal.png}
		\caption{}
		\label{fig:finegrained_aout}
	\end{subfigure}
	\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < 	%%%
\DIFdelendFL \caption{\footnotesize{(a) CDF of FFT Coefficients showing different distributions depending on the class of faults.,(b) Fine-grained Fault Analysis,(c) \textbf{\aout} waveforms showing different behavior for paper, plastic and dust obstructions.}
	}
	\label{}
\DIFdelbeginFL %DIFDELCMD < \vspace{-10pt}
%DIFDELCMD < %%%
\DIFdelendFL \end{figure*}

\subsection{Stage II -- Failure Diagnosis} 

Diagnosing the \textit{cause of failures (\ie class)} requires further investigation of \aout from faulty sensors.
\DIFaddbegin \DIFadd{We combine our understanding of the PIR sensor }\ie \DIFadd{physics from \S\ref{subsec:physics}, failure taxonomy from \S\ref{subsec:taxonomy} and the frequency analysis of failures from \S\ref{subsec:freq_char} and feature analysis from \S\ref{subsec:bh} -- \S\ref{subsec:shap}. 
}\DIFaddend {\bfseries Fig.~\ref{fig:cdf_combined_all}} plots the CDF of FFT coefficients obtained for working sensors and \DIFdelbegin \DIFdel{different }\DIFdelend \DIFaddbegin \DIFadd{various }\DIFaddend faulty sensors. 
The figure shows that although the distribution of working sensors (bottom-most curve) is distinct from failed sensors, different classes of failures have distributions that are not easily separable. 
Thus, relying on merely the FFT is insufficient. 
Consequently, we look at an additional 10 features as described in \S\ref{subsec:bh} --- \S\ref{subsec:shap} and shown in {\bfseries Fig.~\ref{fig:BH_feature_selection}}. 
\DIFdelbegin \DIFdel{Failure diagnosis leverages the combined feature space to identify failure classes according to the taxonomy in \S\ref{subsec:taxonomy}.
}\DIFdelend 




We validated this across the multiple deployments in the wild --- Elevator (\S\ref{subsubsec:elevator}), Lobby (\S\ref{subsubsec:lobby})\DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend Starbucks (\S\ref{subsubsec:starbucks}) \DIFdelbegin \DIFdel{.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\textbf{\DIFdel{Note:}} %DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{and Cafeteria (\S\ref{subsubsec:cafeteria}).
}\DIFaddend Our real-world measurements demonstrate that features of \aout extracted during training and B-H feature selection is robust to variations in shapes and sizes of obstacles.

\begin{comment}
\begin{tcolorbox}[left=1pt,right=1pt,top=1ex,bottom=1pt,boxsep=0pt,
toptitle=0.5ex,bottomtitle=0.5ex]
{\bfseries Summary:} \ins{ML-based models developed considering multiple direct and derived time and frequency domain signal characteristics of \aout are required to diagnose the root cause of the failure in the sensor and point to the subsystem containing the failure.}
\end{tcolorbox}
\end{comment}

\subsection{Stage III -- Fine-Grained Failure Analysis} In fine-grained fault analysis, we point to the \textit{precise reason} for the fault where applicable. For example, in Class III faults it is useful to distinguish between different foreign substances contaminating the lens that can cause poor performance.




To investigate this, we selected the set of faulty sensors identified as Class III faults in 
\DIFdelbegin \DIFdel{stage }\DIFdelend \DIFaddbegin \DIFadd{Stage }\DIFaddend II: some covered with paper, some with plastic tape and some with dust and observe the \aout output closely. 
Although all the failure scenarios result in the obstacle being missed, frequencies present in \aout are different in each case\DIFdelbegin \DIFdel{(}\DIFdelend \DIFaddbegin \DIFadd{, as shown in }\DIFaddend {\bfseries Fig.~\ref{fig:finegrained_aout}}\DIFdelbegin \DIFdel{)}\DIFdelend , due to the distinct thermal absorption characteristics of the materials.
Hence, we observe that the \DIFdelbegin \DIFdel{FFT coefficients }\DIFdelend \DIFaddbegin \aout \DIFadd{features }\DIFaddend can separate Class III failures into different fine-grained sub-classes as shown in {\bfseries Fig.~\ref{fig:finegrained_classification_results}}. 

It is to be noted that fine-grained fault analysis does not work in all cases.
For example, differentiating between a lens puncture (a hole in the lens) and a lens deformation (defect in lens curvature), both examples of Class II failures, is complex. 
This is because both lens puncture and lens deformations lead to blind spots in the frequency spectrum. 
Thus, we need to use knowledge of the subsystem physics before applying the fine-grained analysis.

\DIFaddbegin \noindent \DIFaddend {\bfseries Summary:} \ci The FFT representation of \aout is used to perform binary classification between working and faulty sensors, \cii Considering multiple direct and derived time and frequency domain signal characteristics of \aout can diagnose the cause of failure in the sensor and \ciii Fine-grained fault analysis is possible in select failure cases (\eg Class III) by reanalyzing the \DIFdelbegin \DIFdel{FFT }\DIFdelend \DIFaddbegin \aout \DIFaddend waveforms. 


 \DIFdelbegin %DIFDELCMD < \vspace{-15pt}
%DIFDELCMD < %%%
\DIFdelend \section{Discussion}

\noindent\textbf{Practicality:} \aout is an intrinsic signal that is present in all PIR sensors. 
Commercial sensors typically do not provide easy access to the \aout signal. 
While there exists some commercial sensors (\eg~\cite{panasonic_amn22111,panasonic_amn23111}) that expose \aout, we believe that our work can provide further incentive to other manufacturers. 
In addition, existing sensors can be modified to expose \aout --- most do as a test point on the PCB.
This modification would not incur any additional hardware costs, with the exception of a new pin connector.

\DIFaddbegin \noindent \textbf{\DIFadd{Latency:}} \DIFaddend \sol can precisely determine if a sensor is working or faulty in single time window\DIFdelbegin \DIFdel{comprising }\DIFdelend \DIFaddbegin \DIFadd{, which in our case comprised }\DIFaddend of 1024 samples. Since we sample at 20 Hz, the end-to-end process of data acquisition, processing and inference can be performed in a little over \DIFdelbegin \DIFdel{a }\DIFdelend \DIFaddbegin \DIFadd{one }\DIFaddend minute.


\noindent\textbf{Consistency of behavior:} We observed that the inherent characteristics of the \aout signal, both in time and frequency domains, remain consistent across different manufacturers. This is expected since all PIR sensors use a pyroelectric element \DIFaddbegin \DIFadd{and the physics of operation is deterministic}\DIFaddend .


\noindent\textbf{Design:} We envision \sol to be connected to a Building Monitoring System (BMS) and provide real-time fault detection. We \DIFdelbegin \DIFdel{intend to develop }\DIFdelend \DIFaddbegin \DIFadd{envision developing }\DIFaddend APIs for application developers to build higher-level diagnostic tools on top of \sol.
\DIFdelbegin %DIFDELCMD < \vspace{-5pt}
%DIFDELCMD < %%%
\paragraph{\DIFdel{Acknowledgments}}%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{We would like to thank Denizhan Kara (UIUC) and Kyo Kim (UIUC) for their insights on feature analysis. Further, we are grateful to Kapil Vaidya (MIT), Aditi Partap (Stanford), Hsuan-Chi Kuo (UIUC), Bin-Chou Kao (UIUC) and Ragini Gupta (UIUC) for their detailed feedback. }%DIFDELCMD < \vspace{-5pt}
%DIFDELCMD < \begin{comment}%DIFDELCMD < 
%DIFDELCMD < \section{Insights from Real-world Deployment} 
%DIFDELCMD < \label{sec:lessons}
%DIFDELCMD < 
%DIFDELCMD < \textbf{\ca Fault Detection to Fine-grained fault analysis} Our current scheme relies on FFT-based features of \aout for fault detection. We extended this to failure diagnosis \ie identifying the source of failure using additional features. In Class III failures, we are able to pin-point to the cause such as obstruction due to paper, tape or plastic owning to their different thermal response characteristics.
%DIFDELCMD < 
%DIFDELCMD < 
%DIFDELCMD < 
%DIFDELCMD < \textbf{\cb Generality} Our approach of analyzing physics and combining it with practical failures generalizes to other sensors. The process of finding the right features from physics via Benjamini-Hochberg process and fine-tuning the algorithm with SHAP values can augment existing data-driven ML techniques with the sensing physics to get better fault diagnosis techniques. [need to rewite this]
%DIFDELCMD < 
%DIFDELCMD < \textbf{\cc PIR Sensor Designs} We analyzed commercial PIR sensor designs via websites (\eg digikey, adafruit and mouser electronics~\cite{vendor_websites}). As expected, there is no standard sensor design that is consistent across vendors. We observed that some vendors exposed both the Analog (\aout) and Discrete (\cout) outputs, whereas some others exposed only the Discrete output (\cout). We recommend that sensor vendors bring out the \aout signal as it helps in reliability.
%DIFDELCMD < \end{comment}
%DIFDELCMD <  %%%
\DIFdelend 

\DIFaddbegin \begin{comment}
\section{Insights from Real-world Deployment} 
\label{sec:lessons}

\textbf{\ca Fault Detection to Fine-grained fault analysis} Our current scheme relies on FFT-based features of \aout for fault detection. We extended this to failure diagnosis \ie identifying the source of failure using additional features. In Class III failures, we are able to pin-point to the cause such as obstruction due to paper, tape or plastic owning to their different thermal response characteristics.



\textbf{\cb Generality} Our approach of analyzing physics and combining it with practical failures generalizes to other sensors. The process of finding the right features from physics via Benjamini-Hochberg process and fine-tuning the algorithm with SHAP values can augment existing data-driven ML techniques with the sensing physics to get better fault diagnosis techniques. [need to rewrite this]

\textbf{\cc PIR Sensor Designs} We analyzed commercial PIR sensor designs via websites (\eg digikey, adafruit and mouser electronics~\cite{vendor_websites}). As expected, there is no standard sensor design that is consistent across vendors. We observed that some vendors exposed both the Analog (\aout) and Discrete (\cout) outputs, whereas some others exposed only the Discrete output (\cout). We recommend that sensor vendors bring out the \aout signal as it helps in reliability.
\end{comment}




\section{\DIFadd{Conclusion}} 
\label{sec:concl}
\DIFadd{The approach of using physics in conjunction with machine learning techniques can pave way for a dependable and reliable IoT. The analysis of intrinsic signals allows us to better understand the physics of a sensor that can aid in fault detection, diagnosis and maintenance of sensors. We show that in the case of PIR sensors, the appropriate use of intermediate analog signals offers potential to perform in-situ fault diagnosis thereby reducing costs and improving reliability. Due to lack of standard designs of PIR sensors, we propose that sensor vendors include the }\aout \DIFadd{signal in all PIR sensor designs to aid in the reliability of PIR sensors. }\DIFaddend \bibliographystyle{plain}
\balance
\bibliography{Sections/09_ref_full.bib}
\DIFaddbegin \clearpage 
\setcounter{section}{0}

\section*{\huge{\textsc{Appendix}}}
\label{sec:appendix}





\section{\DIFadd{Frequently Asked Questions (FAQs)}}
\label{sec:app}



\begin{description}[style=nextline]
	\item[\DIFadd{Q: Where does }\sol \textit{\DIFadd{detect and diagnose}} \DIFadd{faults? }] \DIFadd{A: }\sol \DIFadd{performs detection and diagnosis on collected data at the edge device, and does not need any additional hardware. Edge devices are commonly present in sensor deployments and are responsible to aggregate data from multiple sensors and tranmit it to the cloud. We use the edge to execute }\sol\DIFadd{.
	}\item[\DIFadd{Q: Does }\sol \DIFadd{require }\textit{\DIFadd{cloud connectivity}}\DIFadd{?}] 
	\DIFadd{A: }\sol \DIFadd{performs all the computation on the edge and does not require cloud connectivity. As it detects failures on the edge and rejects incorrect data, this saves cloud-edge network bandwidth as well as ensures data from broken sensors do not reach the cloud, thereby enabling better data analytics at the cloud as well. 
	}\item[\DIFadd{Q: Does }\sol \DIFadd{detect faults at runtime? Is it instantaneous?}]
	\DIFadd{A: }\sol \DIFadd{is used to detect failures by analyzing samples over a window of 256 -- 1024 samples }\ie \DIFadd{5 -- 20 seconds at a sampling rate of 50 Hz. Thus, it can be used to detect anomalies at runtime. In addition, }\sol \DIFadd{is non-intrusive and does not involve disassembling or uninstalling the sensor. However, the typical use case is a post-analysis }\eg \DIFadd{once in a day to find out failing sensors since edge devices are typically resource constrained.
	}\item[\DIFadd{Q: Does }\sol \DIFadd{require special sensors?}]
	\DIFadd{A: }\sol \DIFadd{requires a PIR sensor that exposes the }\aout \DIFadd{signal }\ie \DIFadd{output of pyroelectric element. Currently, not all PIR sensor manufacturers expose }\aout \DIFadd{signal in their sensor. Note however that }\textit{\DIFadd{every}} \DIFadd{PIR sensor contains the }\aout \DIFadd{signal, as it is a core part of the pyroelectric element physics. 
	}\item[\DIFadd{Q: What can PIR sensor manufacturers takeaway from }\sol\DIFadd{?}]
	\DIFadd{A: We use this work to make sensor manufacturers include the signal }\aout \DIFadd{in all their sensor designs as it would enable fault detection and diagnosis at the edge.
	}\item[\DIFadd{Q: Are the failures artificial?}]
	\DIFadd{A: It is a criticism that }\sol \DIFadd{handles only artificially-induced failures. However, this is not true. The failures induced are those observed by IoT/Smart Building technicians and engineers who deploy sensors in our buildings in US and India. We recreate these failures on cheap sensors as it is not feasible to perform large-scale deployment with expensive sensors typically seen in modern buildings.
}\item[\DIFadd{Q: Does }\sol \DIFadd{work with high-grade PIR sensors?}]
	\DIFadd{A:  While our work focused on low-cost, commodity, large-scale, cheap deployments of PIR sensors, the physics of sensing is identical in commercial-grade PIR sensors as well. We accessed a PIR sensor from our building ceiling and analyzed the }\aout \DIFadd{waveform by connecting it to an oscilloscope. In our preliminary observations, we saw that the shape of }\aout \DIFadd{is similar to that we saw in low-cost sensors. This similarity in the nature of }\aout \DIFadd{waveforms show promise to that our analysis and techniques can be extended to commercial-grade PIR sensors as well. As each of these sensors cost around \$200, we could not study conduct a study on different failures due to their exorbitant cost.
}\end{description}


























































































  \DIFaddend\end{document}
